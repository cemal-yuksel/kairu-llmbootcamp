"""
Streamlit ile Frontend UygulamasÄ± - DetaylÄ± EÄŸitim Notu
========================================================

Bu modÃ¼l, Streamlit framework'Ã¼ kullanarak LLM (Large Language Model) tabanlÄ± 
bir chatbot ve Ã§eÅŸitli doÄŸal dil iÅŸleme uygulamalarÄ± oluÅŸturmayÄ± gÃ¶sterir.

Kapsanan Konular:
- Streamlit temel bileÅŸenleri ve sayfa yapÄ±landÄ±rmasÄ±
- OpenAI API entegrasyonu
- Session state yÃ¶netimi
- Streaming yanÄ±tlar
- Multi-tab uygulama mimarisi
- Veri gÃ¶rselleÅŸtirme

Gereksinimler:
- streamlit
- openai
- python-dotenv
- pandas
- plotly
"""

# ============================================================================
# KÃœTÃœPHANE Ä°MPORTLARI
# ============================================================================

import streamlit as st  # Streamlit: Web uygulamasÄ± oluÅŸturmak iÃ§in ana framework
from openai import OpenAI  # OpenAI: GPT modelleriyle etkileÅŸim iÃ§in resmi kÃ¼tÃ¼phane
import os  # os: Ä°ÅŸletim sistemi fonksiyonlarÄ± (environment variables iÃ§in)
from dotenv import load_dotenv  # dotenv: .env dosyasÄ±ndan Ã§evre deÄŸiÅŸkenlerini yÃ¼kler
import time  # time: Zaman iÅŸlemleri iÃ§in (ÅŸu an kullanÄ±lmÄ±yor ama gelecek Ã¶zellikler iÃ§in)
import pandas as pd  # pandas: Veri analizi ve manipÃ¼lasyonu iÃ§in
import plotly.express as px  # plotly: Ä°nteraktif grafik ve gÃ¶rselleÅŸtirme iÃ§in

# ============================================================================
# BAÅLANGIÃ‡ YAPILANDIRMASI
# ============================================================================

# Environment variables yÃ¼kle
# .env dosyasÄ±ndan OPENAI_API_KEY gibi gizli bilgileri yÃ¼kler
# Bu sayede API anahtarlarÄ±nÄ± kod iÃ§inde yazmaya gerek kalmaz
load_dotenv()

# OpenAI client oluÅŸtur
# API anahtarÄ± ile OpenAI servislerine baÄŸlantÄ± kurar
# os.getenv(): Ã‡evre deÄŸiÅŸkenlerinden API anahtarÄ±nÄ± okur
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============================================================================
# SAYFA YAPILANDIRMASI
# ============================================================================

# Streamlit sayfasÄ±nÄ±n temel ayarlarÄ±nÄ± yapÄ±landÄ±r
st.set_page_config(
    page_title="LLM Uygulama Demo",  # TarayÄ±cÄ± sekmesinde gÃ¶rÃ¼necek baÅŸlÄ±k
    page_icon="ğŸ¤–",  # TarayÄ±cÄ± sekmesinde gÃ¶rÃ¼necek emoji icon
    layout="wide",  # Sayfa dÃ¼zeni: "wide" tÃ¼m ekranÄ± kullanÄ±r, "centered" ortalanmÄ±ÅŸ
    initial_sidebar_state="expanded"  # Sidebar baÅŸlangÄ±Ã§ta aÃ§Ä±k mÄ± kapalÄ± mÄ±: "expanded" veya "collapsed"
)

# ============================================================================
# SIDEBAR (YAN PANEL) YAPILANDIRMASI
# ============================================================================

# Sidebar: UygulamanÄ±n sol tarafÄ±nda yer alan ayarlar paneli
with st.sidebar:
    # Sidebar baÅŸlÄ±ÄŸÄ±
    st.title("âš™ï¸ Ayarlar")
    
    # Model seÃ§imi dropdown menÃ¼sÃ¼
    # KullanÄ±cÄ±nÄ±n hangi GPT modelini kullanacaÄŸÄ±nÄ± seÃ§mesini saÄŸlar
    model_choice = st.selectbox(
        "Model SeÃ§in:",  # Dropdown etiketi
        ["gpt-3.5-turbo", "gpt-4"],  # SeÃ§enekler listesi
        index=0  # VarsayÄ±lan seÃ§im (0 = ilk eleman = gpt-3.5-turbo)
    )
    
    # Temperature slider'Ä±
    # Temperature: Model yanÄ±tlarÄ±nÄ±n ne kadar yaratÄ±cÄ±/rastgele olacaÄŸÄ±nÄ± kontrol eder
    # 0.0 = Deterministik (her zaman aynÄ± yanÄ±t)
    # 1.0 = Ã‡ok yaratÄ±cÄ± (daha rastgele ve Ã§eÅŸitli yanÄ±tlar)
    temperature = st.slider(
        "Temperature (YaratÄ±cÄ±lÄ±k):",  # Slider etiketi
        min_value=0.0,  # Minimum deÄŸer
        max_value=1.0,  # Maximum deÄŸer
        value=0.7,  # VarsayÄ±lan deÄŸer
        step=0.1  # ArtÄ±ÅŸ miktarÄ±
    )
    
    # Max tokens slider'Ä±
    # Max tokens: YanÄ±tÄ±n maksimum uzunluÄŸunu belirler
    # 1 token â‰ˆ 4 karakter veya 0.75 kelime
    max_tokens = st.slider(
        "Max Tokens (Maksimum uzunluk):",  # Slider etiketi
        min_value=50,  # Minimum 50 token
        max_value=500,  # Maximum 500 token
        value=150,  # VarsayÄ±lan 150 token
        step=50  # 50'lik artÄ±ÅŸlar
    )
    
    # GÃ¶rsel ayÄ±rÄ±cÄ± Ã§izgi
    st.divider()
    
    # API Key kontrolÃ¼ ve kullanÄ±cÄ±ya bilgilendirme
    # Environment variable'dan API key'in yÃ¼klenip yÃ¼klenmediÄŸini kontrol eder
    if not os.getenv("OPENAI_API_KEY"):
        # EÄŸer API key yoksa kÄ±rmÄ±zÄ± hata mesajÄ± gÃ¶ster
        st.error("âš ï¸ API Key bulunamadÄ±! `.env` dosyasÄ±nÄ± kontrol edin.")
    else:
        # EÄŸer API key varsa yeÅŸil baÅŸarÄ± mesajÄ± gÃ¶ster
        st.success("âœ… API Key yÃ¼klendi")
    
    # BaÅŸka bir ayÄ±rÄ±cÄ± Ã§izgi
    st.divider()
    
    # TÃ¼m sohbet geÃ§miÅŸini temizleme butonu
    if st.button("ğŸ—‘ï¸ TÃ¼m GeÃ§miÅŸi Temizle"):
        # Session state'teki mesajlarÄ± boÅŸ liste yap
        st.session_state.messages = []
        # SayfayÄ± yeniden yÃ¼kle (deÄŸiÅŸikliklerin gÃ¶rÃ¼nmesi iÃ§in)
        st.rerun()

# ============================================================================
# SESSION STATE YÃ–NETÄ°MÄ°
# ============================================================================

"""
Session State Nedir?
--------------------
Streamlit her kullanÄ±cÄ± etkileÅŸiminde (buton tÄ±klama, text giriÅŸi vb.) 
scripti baÅŸtan Ã§alÄ±ÅŸtÄ±rÄ±r. Session state, kullanÄ±cÄ± oturumu boyunca
verileri saklamak iÃ§in kullanÄ±lÄ±r.

Ã–rnek: Sohbet geÃ§miÅŸini saklamak iÃ§in session state kullanÄ±yoruz.
Aksi halde her etkileÅŸimde geÃ§miÅŸ mesajlar kaybolur.
"""

# EÄŸer "messages" anahtarÄ± session state'te yoksa, boÅŸ liste oluÅŸtur
# Bu anahtar chatbot mesaj geÃ§miÅŸini saklar
if "messages" not in st.session_state:
    st.session_state.messages = []

# Metin Ã¶zeti saklamak iÃ§in session state anahtarÄ±
# Ã–zetleme iÅŸlemi sonucu burada saklanÄ±r
if "text_summary" not in st.session_state:
    st.session_state.text_summary = ""

# Ã‡eviri sonucu saklamak iÃ§in session state anahtarÄ±
# Ã‡eviri iÅŸlemi sonucu burada saklanÄ±r
if "translation_result" not in st.session_state:
    st.session_state.translation_result = ""

# ============================================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================================

def get_openai_response(prompt, system_prompt="Sen yardÄ±mcÄ± bir asistansÄ±n.", model="gpt-3.5-turbo"):
    """
    OpenAI API'den yanÄ±t al (Normal Mod)
    
    Bu fonksiyon, OpenAI API'ye istek gÃ¶nderir ve tam yanÄ±tÄ± bir seferde alÄ±r.
    Streaming olmadÄ±ÄŸÄ± iÃ§in kullanÄ±cÄ± yanÄ±tÄ±n tamamÄ±nÄ± bekler.
    
    Parametreler:
    -------------
    prompt : str
        KullanÄ±cÄ±nÄ±n sorusu veya isteÄŸi
    system_prompt : str
        Modelin davranÄ±ÅŸÄ±nÄ± belirleyen sistem mesajÄ±
        Ã–rn: "Sen bir Python uzmanÄ±sÄ±n", "Sen Shakespeare gibi konuÅŸ"
    model : str
        KullanÄ±lacak OpenAI model adÄ± (gpt-3.5-turbo veya gpt-4)
    
    DÃ¶ndÃ¼rÃ¼r:
    ---------
    str
        Modelin Ã¼rettiÄŸi yanÄ±t metni veya hata mesajÄ±
    
    Ã–nemli Kavramlar:
    -----------------
    - System Prompt: Modelin kiÅŸiliÄŸini ve davranÄ±ÅŸÄ±nÄ± belirler
    - User Prompt: KullanÄ±cÄ±nÄ±n gerÃ§ek sorusu
    - Messages: Sohbet geÃ§miÅŸini iÃ§eren liste yapÄ±sÄ±
    """
    try:
        # OpenAI API'ye chat completion isteÄŸi gÃ¶nder
        response = client.chat.completions.create(
            model=model,  # KullanÄ±lacak model
            messages=[
                # Sistem mesajÄ±: Modelin rolÃ¼nÃ¼ tanÄ±mlar
                {"role": "system", "content": system_prompt},
                # KullanÄ±cÄ± mesajÄ±: GerÃ§ek soru/istek
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,  # Maksimum yanÄ±t uzunluÄŸu
            temperature=temperature  # YaratÄ±cÄ±lÄ±k seviyesi
        )
        # YanÄ±tÄ±n iÃ§eriÄŸini dÃ¶ndÃ¼r
        # response.choices[0]: Ä°lk (ve genelde tek) yanÄ±t seÃ§eneÄŸi
        # .message.content: YanÄ±tÄ±n metin iÃ§eriÄŸi
        return response.choices[0].message.content
    except Exception as e:
        # Herhangi bir hata olursa (API hatasÄ±, network hatasÄ± vb.)
        # Hata mesajÄ±nÄ± dÃ¶ndÃ¼r
        return f"Hata oluÅŸtu: {str(e)}"


def stream_openai_response(prompt, system_prompt="Sen yardÄ±mcÄ± bir asistansÄ±n.", model="gpt-3.5-turbo"):
    """
    OpenAI API'den streaming yanÄ±t al
    
    Bu fonksiyon, yanÄ±tÄ± parÃ§a parÃ§a (chunk) alÄ±r ve anlÄ±k olarak gÃ¶sterir.
    ChatGPT'nin kelime kelime yazmasÄ± gibi bir efekt saÄŸlar.
    
    Parametreler:
    -------------
    prompt : str
        KullanÄ±cÄ±nÄ±n sorusu
    system_prompt : str
        Sistem mesajÄ±
    model : str
        Model adÄ±
    
    Yields (Generator):
    -------------------
    str
        Åu ana kadar oluÅŸturulan tam yanÄ±t metni
        Her chunk'ta bir Ã¶nceki yanÄ±t + yeni chunk dÃ¶ndÃ¼rÃ¼lÃ¼r
    
    Generator Nedir?
    ----------------
    Normal fonksiyonlar 'return' kullanÄ±r ve bir kez deÄŸer dÃ¶ndÃ¼rÃ¼r.
    Generator fonksiyonlar 'yield' kullanÄ±r ve birden fazla kez deÄŸer dondÃ¼rebilir.
    Bu, streaming iÃ§in idealdir Ã§Ã¼nkÃ¼ her chunk'Ä± ayrÄ± ayrÄ± dÃ¶ndÃ¼rebiliriz.
    """
    try:
        # Streaming modda API isteÄŸi
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            stream=True,  # Ã–NEMLI: Streaming modunu aktif eder
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        # Tam yanÄ±tÄ± saklamak iÃ§in deÄŸiÅŸken
        full_response = ""
        
        # Her chunk'Ä± iÅŸle
        # response bir iterator'dÃ¼r, for dÃ¶ngÃ¼sÃ¼ her chunk'Ä± tek tek alÄ±r
        for chunk in response:
            # Chunk'ta iÃ§erik var mÄ± kontrol et
            # BazÄ± chunk'lar sadece metadata iÃ§erir, content olmayabilir
            if chunk.choices[0].delta.content:
                # Yeni chunk'Ä± mevcut yanÄ±ta ekle
                full_response += chunk.choices[0].delta.content
                # Åu ana kadarki tam yanÄ±tÄ± yield et
                # Bu, Streamlit'te anlÄ±k gÃ¼ncelleme saÄŸlar
                yield full_response
    except Exception as e:
        # Hata durumunda hata mesajÄ±nÄ± yield et
        yield f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# ANA SAYFA
# ============================================================================

# Ana sayfa baÅŸlÄ±ÄŸÄ±
st.title("ğŸ¤– LLM TabanlÄ± Uygulama Ã–rnekleri")
# Alt baÅŸlÄ±k/aÃ§Ä±klama
st.markdown("Bu uygulama Streamlit kullanarak Ã§eÅŸitli LLM uygulamalarÄ±nÄ± gÃ¶sterir.")

# Tab (Sekme) yapÄ±sÄ± oluÅŸtur
# KullanÄ±cÄ± farklÄ± Ã¶zellikler arasÄ±nda geÃ§iÅŸ yapabilir
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ’¬ Chatbot",  # Tab 1: Basit chatbot
    "ğŸŒŠ Streaming Chatbot",  # Tab 2: Streaming Ã¶zellikli chatbot
    "ğŸ“ Metin Ä°ÅŸleme",  # Tab 3: Ã–zetleme ve Ã§eviri
    "ğŸ’» Kod AÃ§Ä±klama",  # Tab 4: Kod analizi
    "ğŸ“Š Veri GÃ¶rselleÅŸtirme"  # Tab 5: Veri analizi ve grafikler
])

# ============================================================================
# TAB 1: Basit Chatbot
# ============================================================================

with tab1:
    """
    Basit Chatbot Tab'Ä±
    -------------------
    Bu tab, geleneksel chatbot arayÃ¼zÃ¼nÃ¼ gÃ¶sterir.
    KullanÄ±cÄ± mesaj gÃ¶nderir, bot yanÄ±t verir.
    TÃ¼m mesaj geÃ§miÅŸi saklanÄ±r ve gÃ¶sterilir.
    """
    
    # Tab baÅŸlÄ±ÄŸÄ±
    st.header("ğŸ’¬ Basit Chatbot")
    st.markdown("### Basit chatbot arayÃ¼zÃ¼")
    
    # Mesaj geÃ§miÅŸini gÃ¶ster
    # Session state'teki her mesajÄ± dÃ¶ngÃ¼ ile gÃ¶ster
    for message in st.session_state.messages:
        # Chat mesaj balonu oluÅŸtur
        # Role: "user" (kullanÄ±cÄ±) veya "assistant" (bot)
        with st.chat_message(message["role"]):
            # Mesaj iÃ§eriÄŸini gÃ¶ster
            st.markdown(message["content"])
    
    # Yeni mesaj input alanÄ±
    # := operatÃ¶rÃ¼: Walrus operator, atama ve kontrol aynÄ± anda
    # KullanÄ±cÄ± mesaj girip Enter'a basarsa prompt deÄŸiÅŸkenine atanÄ±r
    if prompt := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        # KullanÄ±cÄ± mesajÄ±nÄ± session state'e ekle
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # KullanÄ±cÄ± mesajÄ±nÄ± ekranda gÃ¶ster
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Bot yanÄ±tÄ±nÄ± al ve gÃ¶ster
        with st.chat_message("assistant"):
            # OpenAI'dan yanÄ±t al (normal mod, streaming deÄŸil)
            response = get_openai_response(prompt, model=model_choice)
            # YanÄ±tÄ± ekranda gÃ¶ster
            st.markdown(response)
            # Bot yanÄ±tÄ±nÄ± session state'e ekle
            st.session_state.messages.append({"role": "assistant", "content": response})

# ============================================================================
# TAB 2: Streaming Chatbot
# ============================================================================

with tab2:
    """
    Streaming Chatbot Tab'Ä±
    -----------------------
    Bu tab, yanÄ±tlarÄ±n kelime kelime gÃ¶sterildiÄŸi chatbot'u gÃ¶sterir.
    ChatGPT'nin gerÃ§ek zamanlÄ± yazma efekti burada uygulanÄ±r.
    
    Ã–nemli: Tab 1'den ayrÄ± bir mesaj geÃ§miÅŸi kullanÄ±r (streaming_messages)
    """
    
    st.header("ğŸŒŠ Streaming Chatbot")
    st.markdown("### Streaming output ile chatbot")
    
    # Streaming mesaj geÃ§miÅŸi iÃ§in ayrÄ± session state
    # Her tab'Ä±n kendi geÃ§miÅŸi olmasÄ± iÃ§in
    if "streaming_messages" not in st.session_state:
        st.session_state.streaming_messages = []
    
    # Mesaj geÃ§miÅŸini gÃ¶ster
    for message in st.session_state.streaming_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Yeni mesaj input
    if streaming_prompt := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n... (Streaming)"):
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.streaming_messages.append({"role": "user", "content": streaming_prompt})
        with st.chat_message("user"):
            st.markdown(streaming_prompt)
        
        # Bot streaming yanÄ±tÄ±nÄ± al ve gÃ¶ster
        with st.chat_message("assistant"):
            # BoÅŸ placeholder oluÅŸtur
            # Bu placeholder, stream sÄ±rasÄ±nda sÃ¼rekli gÃ¼ncellenecek
            message_placeholder = st.empty()
            full_response = ""
            
            # Stream generator'Ä±ndan her chunk'Ä± al
            for chunk in stream_openai_response(streaming_prompt, model=model_choice):
                full_response = chunk
                # YanÄ±tÄ± gÃ¶ster, sonuna cursor (â–Œ) ekle
                # Bu, "yazÄ±yor..." efekti verir
                message_placeholder.markdown(full_response + "â–Œ")
            
            # Stream bittikten sonra cursor'Ä± kaldÄ±r
            message_placeholder.markdown(full_response)
            # Tam yanÄ±tÄ± session state'e ekle
            st.session_state.streaming_messages.append({"role": "assistant", "content": full_response})
    
    # Streaming geÃ§miÅŸini temizle butonu
    if st.button("ğŸ—‘ï¸ Streaming GeÃ§miÅŸini Temizle"):
        st.session_state.streaming_messages = []
        st.rerun()

# ============================================================================
# TAB 3: Metin Ä°ÅŸleme
# ============================================================================

with tab3:
    """
    Metin Ä°ÅŸleme Tab'Ä±
    ------------------
    Ä°ki ana Ã¶zellik:
    1. Metin Ã–zetleme: Uzun metinleri Ã¶zetler
    2. Metin Ã‡evirisi: Metinleri farklÄ± dillere Ã§evirir
    
    Ä°ki sÃ¼tunlu (column) layout kullanÄ±r
    """
    
    st.header("ğŸ“ Metin Ä°ÅŸleme")
    
    # Ä°ki sÃ¼tun oluÅŸtur (yan yana layout)
    # SÃ¼tunlar eÅŸit geniÅŸlikte (varsayÄ±lan)
    col1, col2 = st.columns(2)
    
    # ---- SOL SÃœTUN: Metin Ã–zetleme ----
    with col1:
        st.subheader("ğŸ“„ Metin Ã–zetleme")
        
        # Ã‡ok satÄ±rlÄ± text input alanÄ±
        text_input = st.text_area(
            "Ã–zetlemek istediÄŸiniz metni yazÄ±n:",
            height=200,  # Piksel cinsinden yÃ¼kseklik
            placeholder="Metninizi buraya yazÄ±n..."  # BoÅŸken gÃ¶sterilen ipucu
        )
        
        # Ã–zetle butonu
        # type="primary" mavi renkli, vurgulu buton yapar
        if st.button("Ã–zetle", type="primary"):
            # Metin girilmiÅŸ mi kontrol et
            if text_input:
                # Spinner: Ä°ÅŸlem sÄ±rasÄ±nda animasyon gÃ¶ster
                with st.spinner("Ã–zetleme yapÄ±lÄ±yor..."):
                    # Ã–zel prompt ile OpenAI'dan Ã¶zet al
                    summary = get_openai_response(
                        f"Bu metni Ã¶zetle:\n\n{text_input}",
                        "Sen bir metin Ã¶zetleme uzmanÄ±sÄ±n. Verilen metni kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle.",
                        model=model_choice
                    )
                    # Ã–zeti session state'e kaydet
                    st.session_state.text_summary = summary
                    # BaÅŸarÄ± mesajÄ± gÃ¶ster
                    st.success("Ã–zetleme tamamlandÄ±!")
        
        # EÄŸer Ã¶zet varsa gÃ¶ster
        if st.session_state.text_summary:
            # Read-only text area (dÃ¼zenlenemez)
            st.text_area("Ã–zet:", value=st.session_state.text_summary, height=150)
    
    # ---- SAÄ SÃœTUN: Metin Ã‡evirisi ----
    with col2:
        st.subheader("ğŸŒ Metin Ã‡eviri")
        
        # Ã‡evrilecek metin input'u
        translate_input = st.text_area(
            "Ã‡evirmek istediÄŸiniz metni yazÄ±n:",
            height=150,
            placeholder="Ã‡evrilecek metni buraya yazÄ±n..."
        )
        
        # Hedef dil seÃ§imi dropdown
        target_language = st.selectbox(
            "Hedef Dil:",
            ["Ä°ngilizce", "FransÄ±zca", "Almanca", "Ä°spanyolca", "Japonca", "TÃ¼rkÃ§e"]
        )
        
        # Ã‡evir butonu
        if st.button("Ã‡evir", type="primary"):
            if translate_input:
                with st.spinner("Ã‡eviri yapÄ±lÄ±yor..."):
                    # System prompt'ta hedef dili belirt
                    translation = get_openai_response(
                        translate_input,
                        f"Sen bir Ã§evirmensin. Verilen metni {target_language} diline Ã§evir.",
                        model=model_choice
                    )
                    # Ã‡eviriyi session state'e kaydet
                    st.session_state.translation_result = translation
                    st.success("Ã‡eviri tamamlandÄ±!")
        
        # Ã‡eviri sonucunu gÃ¶ster
        if st.session_state.translation_result:
            st.text_area("Ã‡eviri:", value=st.session_state.translation_result, height=150)

# ============================================================================
# TAB 4: Kod AÃ§Ä±klama
# ============================================================================

with tab4:
    """
    Kod AÃ§Ä±klama Tab'Ä±
    -------------------
    ProgramcÄ±lar iÃ§in kod analiz aracÄ±.
    Girilen kodu satÄ±r satÄ±r aÃ§Ä±klar.
    FarklÄ± programlama dillerini destekler.
    """
    
    st.header("ğŸ’» Kod AÃ§Ä±klama")
    st.markdown("### Kod aÃ§Ä±klama aracÄ±")
    
    # Programlama dili seÃ§imi
    code_language = st.selectbox(
        "Programlama Dili:",
        ["Python", "JavaScript", "Java", "C++", "Go", "Rust"],
        index=0  # Python varsayÄ±lan
    )
    
    # Kod input alanÄ±
    code_input = st.text_area(
        "AÃ§Ä±klamak istediÄŸiniz kodu yazÄ±n:",
        height=300,  # YÃ¼ksek alan (kod iÃ§in)
        placeholder=f"# {code_language} kodunuzu buraya yazÄ±n..."
    )
    
    # AÃ§Ä±kla butonu
    if st.button("AÃ§Ä±kla", type="primary"):
        if code_input:
            with st.spinner("Kod aÃ§Ä±klamasÄ± oluÅŸturuluyor..."):
                # Kodu markdown code block formatÄ±nda gÃ¶nder
                # Backtick'ler (```) ile kod bloÄŸu oluÅŸtur
                explanation = get_openai_response(
                    f"Bu kodu aÃ§Ä±kla:\n\n```{code_language.lower()}\n{code_input}\n```",
                    f"Sen bir {code_language} programlama uzmanÄ±sÄ±n. Verilen kodu detaylÄ± ÅŸekilde aÃ§Ä±kla.",
                    model=model_choice
                )
                st.success("AÃ§Ä±klama oluÅŸturuldu!")
                st.markdown("### ğŸ“– AÃ§Ä±klama:")
                # Markdown format destekler (bold, italik, kod bloklarÄ± vb.)
                st.markdown(explanation)
        else:
            # Kod girilmemiÅŸse uyarÄ± gÃ¶ster
            st.warning("LÃ¼tfen kod girin!")

# ============================================================================
# TAB 5: Veri GÃ¶rselleÅŸtirme
# ============================================================================

with tab5:
    """
    Veri GÃ¶rselleÅŸtirme Tab'Ä±
    -------------------------
    LLM ile veri analizi ve Plotly ile gÃ¶rselleÅŸtirme kombinasyonu.
    
    Ã–zellikler:
    - Ã–rnek veri gÃ¶sterimi
    - LLM ile veri analizi
    - Ä°nteraktif grafikler (Plotly)
    """
    
    st.header("ğŸ“Š Veri GÃ¶rselleÅŸtirme")
    st.markdown("### LLM ile veri analizi ve gÃ¶rselleÅŸtirme")
    
    # Ã–rnek veri dictionary'si oluÅŸtur
    sample_data = {
        "ÃœrÃ¼n": ["A", "B", "C", "D", "E"],  # ÃœrÃ¼n isimleri
        "SatÄ±ÅŸ": [100, 150, 200, 120, 180],  # SatÄ±ÅŸ rakamlarÄ±
        "Kategori": ["Elektronik", "Giyim", "Elektronik", "Giyim", "Elektronik"]  # Kategoriler
    }
    
    # Dictionary'yi pandas DataFrame'e Ã§evir
    # DataFrame: Tablo formatÄ±nda veri yapÄ±sÄ± (Excel gibi)
    df = pd.DataFrame(sample_data)
    
    # Veri tablosunu gÃ¶ster
    st.subheader("Ã–rnek Veri")
    # use_container_width yerine width='stretch' kullanÄ±mÄ±
    st.dataframe(df, width='stretch')
    
    # Veri analizi iÃ§in kullanÄ±cÄ± sorusu
    analysis_prompt = st.text_area(
        "Veri analizi iÃ§in soru sorun:",
        placeholder="Ã–rn: Bu verilerde hangi kategoride en Ã§ok satÄ±ÅŸ var?",
        height=100
    )
    
    # Analiz Et butonu
    if st.button("Analiz Et", type="primary"):
        if analysis_prompt:
            with st.spinner("Analiz yapÄ±lÄ±yor..."):
                # DataFrame'i string formatÄ±na Ã§evir
                # LLM'in okuyabilmesi iÃ§in tablo formatÄ±nda string
                data_str = df.to_string()
                
                # Veri ve soruyu LLM'e gÃ¶nder
                response = get_openai_response(
                    f"Bu veri tablosunu analiz et:\n\n{data_str}\n\nSoru: {analysis_prompt}",
                    "Sen bir veri analiz uzmanÄ±sÄ±n. Verilen veriyi analiz et ve yorum yap.",
                    model=model_choice
                )
                
                # Analiz sonucunu gÃ¶ster
                st.markdown("### ğŸ“Š Analiz Sonucu:")
                st.markdown(response)
                
                # GÃ¶rselleÅŸtirmeler
                st.markdown("### ğŸ“ˆ GÃ¶rselleÅŸtirme:")
                
                # Bar chart (SÃ¼tun grafiÄŸi)
                # Plotly Express: HÄ±zlÄ± ve kolay grafik oluÅŸturma
                fig_bar = px.bar(
                    df,  # Veri kaynaÄŸÄ±
                    x="ÃœrÃ¼n",  # X ekseni
                    y="SatÄ±ÅŸ",  # Y ekseni
                    color="Kategori",  # Renk kategorisi
                    title="ÃœrÃ¼n SatÄ±ÅŸlarÄ±"  # Grafik baÅŸlÄ±ÄŸÄ±
                )
                # GrafiÄŸi gÃ¶ster, container geniÅŸliÄŸini kullan
                st.plotly_chart(fig_bar, use_container_width=True)
                
                # Pie chart (Pasta grafiÄŸi)
                # Ã–nce kategorilere gÃ¶re topla
                category_sales = df.groupby("Kategori")["SatÄ±ÅŸ"].sum().reset_index()
                
                fig_pie = px.pie(
                    category_sales,  # Toplam veri
                    values="SatÄ±ÅŸ",  # DeÄŸerler
                    names="Kategori",  # Etiketler
                    title="Kategori BazÄ±nda SatÄ±ÅŸ DaÄŸÄ±lÄ±mÄ±"
                )
                st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.warning("LÃ¼tfen bir soru girin!")

# ============================================================================
# FOOTER (Sayfa AltÄ±)
# ============================================================================

# GÃ¶rsel ayÄ±rÄ±cÄ± Ã§izgi
st.divider()

# Alt bilgi notu
st.markdown(
    """
    ---
    **Not**: Bu uygulama OpenAI API kullanmaktadÄ±r. API key'inizi `.env` dosyasÄ±na eklemeyi unutmayÄ±n.
    
    **GeliÅŸtirici Ä°puÃ§larÄ±:**
    - Session state: KullanÄ±cÄ± verilerini saklar
    - st.rerun(): SayfayÄ± yeniden yÃ¼kler
    - Generator fonksiyonlar: Streaming iÃ§in idealdir
    - Plotly: Ä°nteraktif grafikler iÃ§in kullanÄ±lÄ±r
    - Tabs: FarklÄ± Ã¶zellikleri organize eder
    """
)
