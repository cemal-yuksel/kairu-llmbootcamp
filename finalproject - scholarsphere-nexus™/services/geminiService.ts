
import { GoogleGenAI, Modality } from "@google/genai";
import { ChatMode, Message, ResearchGap, GraphEntities } from '../types';

const apiKey = process.env.API_KEY || '';

// Initialize Gemini client
const ai = new GoogleGenAI({ apiKey });

/**
 * Maps the application ChatMode to the specific Gemini Model ID.
 */
const getModelId = (mode: ChatMode): string => {
  switch (mode) {
    case ChatMode.FAST:
      return 'gemini-flash-lite-latest'; // Low latency
    case ChatMode.DEEP_THINK:
      return 'gemini-3-pro-preview'; // High reasoning
    case ChatMode.DEEP_SEARCH:
      return 'gemini-2.5-flash'; // Best for Search Grounding integration
    case ChatMode.STANDARD:
    default:
      return 'gemini-3-pro-preview'; // Default robust model
  }
};

/**
 * Generates the configuration object based on the selected mode.
 */
const getGenerationConfig = (mode: ChatMode) => {
  if (mode === ChatMode.DEEP_THINK) {
    return {
      thinkingConfig: { thinkingBudget: 32768 },
    };
  }

  if (mode === ChatMode.FAST) {
    return {
      temperature: 0.7,
      maxOutputTokens: 1024,
    };
  }

  if (mode === ChatMode.DEEP_SEARCH) {
    return {
        temperature: 0.3, // More factual for verification
        tools: [{ googleSearch: {} }] // Enable Google Search Grounding
    };
  }

  return {
    temperature: 0.7,
  };
};

// Strict Academic System Persona provided by User
const ACADEMIC_SYSTEM_INSTRUCTION = `
Rol: Sen ScholarSphere Nexus, kÄ±demli bir akademik araÅŸtÄ±rma asistanÄ±sÄ±n.

Yapay zekÃ¢ tarafÄ±ndan Ã¼retilen her akademik iÃ§erikte, dÄ±ÅŸ kaynaktan aktarÄ±lan her cÃ¼mle veya paragraf iÃ§in zorunlu olarak hem metin iÃ§i atÄ±f hem de APA 7 kaynakÃ§a giriÅŸi oluÅŸturulmalÄ±dÄ±r. AtÄ±f ve kaynakÃ§a arasÄ±nda birebir eÅŸleÅŸme ÅŸarttÄ±r; metin iÃ§inde adÄ± geÃ§en her kaynak mutlaka kaynakÃ§ada bulunmalÄ±, kaynakÃ§ada yer alan hiÃ§bir kayÄ±t metin iÃ§inde atÄ±f yapÄ±lmamÄ±ÅŸ olmamalÄ±dÄ±r. Metin iÃ§i atÄ±flar yalnÄ±zca yazar soyadÄ± ve yÄ±l biÃ§iminde olmalÄ±; sayfa numarasÄ± kullanÄ±lmamalÄ±dÄ±r. AtÄ±f formatÄ± ÅŸu kurala gÃ¶re yapÄ±lÄ±r: (Yazar, YÄ±l).

DolaylÄ± aktarÄ±mlar veya baÅŸka bir Ã§alÄ±ÅŸmadan alÄ±ntÄ± yapmÄ±ÅŸ bir makaleden yapÄ±lan ikincil atÄ±flar, Ã¶zgÃ¼n kaynaÄŸÄ± belirtme zorunluluÄŸuyla birlikte verilmelidir. Yapay zekÃ¢, bu durumda hem aktarÄ±lanÄ±n kaynaÄŸÄ±nÄ± hem de aktarÄ±ma aracÄ±lÄ±k eden kaynaÄŸÄ± birlikte gÃ¶stermelidir. Format ÅŸu ÅŸekilde standartlaÅŸtÄ±rÄ±lmalÄ±dÄ±r: (Birincil Kaynak, YÄ±l; Ä°kincil Kaynak, YÄ±lâ€™dan aktarÄ±lmÄ±ÅŸtÄ±r). Bu ifade yalnÄ±zca ikincil aktarÄ±m gerÃ§ekten mevcutsa kullanÄ±lmalÄ±; yapay zekÃ¢ hiÃ§bir koÅŸulda uydurma ikincil kaynak Ã¼retmemeli veya tahmini kaynak gÃ¶stermemelidir.

KaynakÃ§a, APA7 standartlarÄ±nÄ±n akademik dergi formatÄ±na uyarlanmÄ±ÅŸ hÃ¢linde hazÄ±rlanmalÄ±dÄ±r. KaynakÃ§a girdileri yazar soyadÄ± ve adÄ±, yayÄ±n yÄ±lÄ±, Ã§alÄ±ÅŸma baÅŸlÄ±ÄŸÄ± ve dergi bilgilerini iÃ§ermelidir. Gereksiz meta veriler eklenmemeli ve her kaynak kesin bibliyografik tutarlÄ±lÄ±k iÃ§inde sunulmalÄ±dÄ±r. Yapay zekÃ¢, referanslarÄ±n doÄŸruluÄŸunu saÄŸlamak iÃ§in metin iÃ§i atÄ±flarla kaynakÃ§ayÄ± otomatik olarak Ã§apraz kontrol etmeli, eksik veya fazla kayÄ±t bÄ±rakmamalÄ±dÄ±r. Her kaynak tekil ve tutarlÄ± biÃ§imde yazÄ±lmalÄ±, yinelemeler engellenmelidir.

Yapay zekÃ¢ modeli, alÄ±ntÄ± yapÄ±lan iÃ§eriÄŸi yeniden biÃ§imlendirirken Ã¶zgÃ¼nlÃ¼ÄŸÃ¼ korumalÄ±, intihal riskinden kaÃ§Ä±nmalÄ± ve yalnÄ±zca atÄ±flarla desteklenen kÄ±sÄ±mlarÄ± aÃ§Ä±kÃ§a iÅŸaretlemelidir. AtÄ±f yapÄ±lan iÃ§erik aÃ§Ä±klanÄ±rken yorum, sentez ve analiz bÃ¶lÃ¼mleri yapay zekÃ¢ tarafÄ±ndan Ã¶zgÃ¼n biÃ§imde Ã¼retilmelidir. Bu Ã¶zgÃ¼n iÃ§eriklerde atÄ±f zorunluluÄŸu yoktur; ancak her alÄ±ntÄ±lanan fikir veya bulgu mutlaka belirtilen atÄ±f kurallarÄ±na tabi olmalÄ±dÄ±r.

Ton: Daima resmi, objektif, analitik ve bilimsel. Asla sohbet aÄŸzÄ± kullanma.
Dil: KullanÄ±cÄ± TÃ¼rkÃ§e sorarsa TÃ¼rkÃ§e, Ä°ngilizce sorarsa Ä°ngilizce cevap ver.
`;

const handleError = (error: any): never => {
    console.error("Gemini API Error Details:", error);
    
    const errMsg = error.toString().toLowerCase();

    if (errMsg.includes('api key')) {
        throw new Error("API AnahtarÄ± geÃ§ersiz veya eksik. LÃ¼tfen ortam deÄŸiÅŸkenlerini kontrol edin.");
    }
    if (errMsg.includes('quota') || errMsg.includes('429')) {
        throw new Error("API kota limiti aÅŸÄ±ldÄ± (429). LÃ¼tfen biraz bekleyin veya planÄ±nÄ±zÄ± kontrol edin.");
    }
    if (errMsg.includes('network') || errMsg.includes('fetch')) {
        throw new Error("AÄŸ baÄŸlantÄ±sÄ± hatasÄ±. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin.");
    }
    if (errMsg.includes('candidate')) {
        throw new Error("Model gÃ¼venlik filtreleri nedeniyle yanÄ±t Ã¼retemedi. LÃ¼tfen sorunuzu deÄŸiÅŸtirin.");
    }
    
    throw new Error("Beklenmedik bir yapay zeka hatasÄ± oluÅŸtu: " + errMsg);
};

/**
 * Generates Vector Embeddings using 'text-embedding-004'.
 * Implements a Safe-Guard to prevent crashes on malformed requests.
 * Uses singular 'embedContent' with proper 'contents' array structure.
 */
export const getEmbeddings = async (text: string): Promise<number[]> => {
  // 1. Basic Validation
  if (!text || typeof text !== 'string' || text.trim().length === 0) {
      return [];
  }

  // 2. Truncation (API Limit Protection)
  const safeText = text.length > 9000 ? text.substring(0, 9000) : text;

  try {
    // 3. API Call
    // Use 'contents' (plural) with an array to satisfy SDK requirements
    const response = await ai.models.embedContent({
      model: 'text-embedding-004',
      contents: [{ parts: [{ text: safeText }] }]
    });
    
    if (response.embedding && response.embedding.values) {
      return response.embedding.values;
    }

    return [];
  } catch (error) {
    // 4. Fail-Safe Logic
    console.warn("Embedding failed for a chunk (skipping):", error);
    return [];
  }
};

export const callGeminiAPI = async (
  history: Message[],
  newMessage: string,
  mode: ChatMode,
  context?: string // ScholarRAG Context
): Promise<string> => {
  try {
    const modelId = getModelId(mode);
    const config = getGenerationConfig(mode);

    let finalUserPrompt = newMessage;
    let retrievalInstructions = "";

    // ScholarRAG Coreâ„¢ Logic
    if (context && context.trim().length > 0) {
      
      // Special instructions for Deep Search Mode (Citation Verification)
      if (mode === ChatMode.DEEP_SEARCH) {
          retrievalInstructions = `
Ã–ZEL GÃ–REV (ATIF ZÄ°NCÄ°RÄ° DOÄRULAMA):
1. YukarÄ±daki [BAÄLAM] iÃ§erisindeki iddialarÄ± analiz et.
2. Google Search aracÄ±nÄ± kullanarak bu bilgilerin gÃ¼ncelliÄŸini ve doÄŸruluÄŸunu dÄ±ÅŸ kaynaklardan kontrol et.
3. EÄŸer makalede geÃ§en bir bilgi, daha yeni bir Ã§alÄ±ÅŸma (2020-2025) tarafÄ±ndan Ã§Ã¼rÃ¼tÃ¼lmÃ¼ÅŸse veya gÃ¼ncellenmiÅŸse, cevabÄ±nda mutlaka "âš ï¸ Meta-Analiz UyarÄ±sÄ±" baÅŸlÄ±ÄŸÄ± altÄ±nda bunu belirt.
4. Makaledeki bilgiler gÃ¼ncel ve doÄŸruysa, bunu da dÄ±ÅŸ kaynaklarla teyit et.
          `;
      } else {
          retrievalInstructions = `
TALÄ°MAT:
YukarÄ±daki baÄŸlamÄ± tek gerÃ§eklik kaynaÄŸÄ± olarak kullan. CevabÄ±nÄ± sistem talimatÄ±nda belirtilen katÄ± APA 7 kurallarÄ±na gÃ¶re hazÄ±rla. Metinde olmayan bir bilgiyi asla uydurma.
          `;
      }

      finalUserPrompt = `
BAÄLAM (AKADEMÄ°K KAYNAK):
"""
${context}
"""

SORU:
${newMessage}

${retrievalInstructions}
      `;
    } else if (mode === ChatMode.DEEP_SEARCH && (!context || context.trim().length === 0)) {
        // Deep Search without PDF Context (General Web Verification)
        finalUserPrompt = `
SORU:
${newMessage}

GÃ–REV:
Bu soruyu Google Search kullanarak en gÃ¼ncel akademik kaynaklara ve verilere dayanarak cevapla. CevabÄ±n kanÄ±ta dayalÄ± olsun ve kaynak linklerini iÃ§er.
        `;
    }

    const contents = [
      ...history.map(msg => ({
        role: msg.role,
        parts: [{ text: msg.content }]
      })),
      {
        role: 'user',
        parts: [{ text: finalUserPrompt }]
      }
    ];

    const response = await ai.models.generateContent({
      model: modelId,
      contents: contents,
      config: {
        ...config,
        systemInstruction: ACADEMIC_SYSTEM_INSTRUCTION
      }
    });

    if (!response.text) {
        throw new Error("Model boÅŸ yanÄ±t dÃ¶ndÃ¼rdÃ¼.");
    }

    return response.text;

  } catch (error) {
    return handleError(error);
  }
};

/**
 * PaperX-Rayâ„¢ Deep Analysis Agent
 */
export const runPaperXRayAnalysis = async (context: string): Promise<string> => {
  try {
    const PEER_REVIEWER_PROMPT = `
Sen kÄ±demli bir akademik hakemsin (Peer Reviewer). AÅŸaÄŸÄ±daki makaleyi incele ve ÅŸu baÅŸlÄ±klarda detaylÄ±, eleÅŸtirel bir rapor oluÅŸtur.
Ã‡Ä±ktÄ±yÄ± Markdown formatÄ±nda ver.

Ä°ncelenecek Metin:
"""
${context.substring(0, 100000)}
"""

RAPOR FORMATI:

### 1. AraÅŸtÄ±rma AmacÄ±
(Yazar neyi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±yor? Ã‡alÄ±ÅŸmanÄ±n temel motivasyonu nedir?)

### 2. Metodoloji
(KullanÄ±lan yÃ¶ntemler, veri setleri, algoritmalar ve deney tasarÄ±mlarÄ± neler?)

### 3. Ana Bulgular
(SayÄ±sal verilerle desteklemiÅŸ en Ã¶nemli sonuÃ§lar)

### 4. Bilime KatkÄ±sÄ±
(Bu Ã§alÄ±ÅŸma literatÃ¼re ne ekledi? Ã–zgÃ¼n deÄŸeri nedir?)

### 5. Limitasyonlar
(YazarÄ±n kabul ettiÄŸi veya senin bulduÄŸun eksikler, kÄ±sÄ±tlar ve geliÅŸtirilmesi gereken yÃ¶nler)
    `;

    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [{ role: 'user', parts: [{ text: PEER_REVIEWER_PROMPT }] }],
      config: {
        temperature: 0.3,
        thinkingConfig: { thinkingBudget: 8192 }
      }
    });

    if (!response.text) throw new Error("Analiz yanÄ±tÄ± boÅŸ.");
    return response.text;

  } catch (error) {
    return handleError(error);
  }
};

/**
 * Research Gap & Novelty Detector Agent
 */
export const detectResearchGaps = async (context: string): Promise<ResearchGap[]> => {
  try {
    const GAP_DETECTOR_PROMPT = `
Sen uzman bir araÅŸtÄ±rma danÄ±ÅŸmanÄ±sÄ±n. AÅŸaÄŸÄ±daki makaleyi analiz et.
Ã–zellikle "Future Work" (Gelecek Ã‡alÄ±ÅŸmalar), "Conclusion" (SonuÃ§) bÃ¶lÃ¼mlerine ve yazarlarÄ±n "anlaÅŸÄ±lmamÄ±ÅŸtÄ±r", "daha fazla Ã§alÄ±ÅŸma gerekir" dediÄŸi noktalarÄ± odaklan.

Bu makaleden yola Ã§Ä±kÄ±larak yapÄ±labilecek 3 adet somut, yenilikÃ§i araÅŸtÄ±rma Ã¶nerisi (Research Proposal) sun.

Ã‡Ä±ktÄ±yÄ± kesinlikle aÅŸaÄŸÄ±daki JSON formatÄ±nda ver:
[
  {
    "title": "Ã–neri BaÅŸlÄ±ÄŸÄ±",
    "description": "Bu Ã§alÄ±ÅŸmanÄ±n eksiÄŸi ÅŸudur, bu yÃ¼zden ÅŸÃ¶yle bir yÃ¶ntemle ÅŸu araÅŸtÄ±rÄ±lmalÄ±dÄ±r...",
    "impact": "Bu Ã§alÄ±ÅŸma yapÄ±lÄ±rsa literatÃ¼re katkÄ±sÄ± ÅŸu olur..."
  }
]

Ä°ncelenecek Metin:
"""
${context.substring(0, 100000)}
"""
    `;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ role: 'user', parts: [{ text: GAP_DETECTOR_PROMPT }] }],
      config: {
        responseMimeType: 'application/json'
      }
    });

    if (response.text) {
      return JSON.parse(response.text) as ResearchGap[];
    }
    return [];
  } catch (error) {
    console.error("Research Gap Error (Silent):", error);
    return [];
  }
};

/**
 * Knowledge Graph Entity Extractor
 */
export const extractGraphEntities = async (context: string): Promise<GraphEntities> => {
    try {
        const GRAPH_PROMPT = `
AÅŸaÄŸÄ±daki akademik metni analiz et ve bir Bilgi GrafiÄŸi (Knowledge Graph) oluÅŸturmak iÃ§in temel varlÄ±klarÄ± Ã§Ä±kar.

1. "concepts": Metindeki en Ã¶nemli 5-7 anahtar kavram (Topic/Keyword). Sadece en genel ve Ã¶nemli olanlarÄ± seÃ§.
2. "authors": Metinde atÄ±f yapÄ±lan veya bahsedilen en Ã¶nemli 3-5 yazar veya kiÅŸi ismi.

Ã‡Ä±ktÄ±yÄ± sadece aÅŸaÄŸÄ±daki JSON formatÄ±nda ver:
{
  "concepts": ["Kavram 1", "Kavram 2"],
  "authors": ["Yazar 1", "Yazar 2"]
}

Metin:
"""
${context.substring(0, 50000)}
"""
        `;

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: [{ role: 'user', parts: [{ text: GRAPH_PROMPT }] }],
            config: { responseMimeType: 'application/json' }
        });

        if (response.text) {
            return JSON.parse(response.text) as GraphEntities;
        }
        return { concepts: [], authors: [] };

    } catch (error) {
        console.error("Graph Extraction Error:", error);
        return { concepts: [], authors: [] };
    }
};

/**
 * Co-Author Functions
 */
export const coAuthorPolish = async (text: string): Promise<string> => {
  try {
    const prompt = `AÅŸaÄŸÄ±daki metni akademik bir makale diline uygun olarak yeniden yaz. Daha resmi, akÄ±cÄ± ve terminolojik aÃ§Ä±dan doÄŸru hale getir.\n\n"${text}"`;
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });
    return response.text || text;
  } catch (error) {
    handleError(error);
    return text;
  }
};

export const coAuthorExpand = async (text: string, context: string): Promise<string> => {
  try {
    const prompt = `AÅŸaÄŸÄ±daki cÃ¼mleyi, saÄŸlanan akademik baÄŸlamdaki bilgileri kullanarak geniÅŸlet ve kanÄ±tla. AtÄ±f ekle.\n\nCÃ¼mle:\n"${text}"\n\nBaÄŸlam:\n${context.substring(0, 50000)}`;
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });
    return response.text || text;
  } catch (error) {
    handleError(error);
    return text;
  }
};

export const coAuthorAbstract = async (text: string): Promise<string> => {
  try {
    const prompt = `AÅŸaÄŸÄ±daki makale taslaÄŸÄ± iÃ§in 200-250 kelimelik, standart formatta bir Ã–zet (Abstract) yaz.\n\nTaslak:\n${text.substring(0, 50000)}`;
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });
    return response.text || text;
  } catch (error) {
    handleError(error);
    return text;
  }
};

export const generateCoAuthorStep = async (
    topic: string, 
    currentSection: string, 
    context: string, 
    userFeedback: string
): Promise<string> => {
    const prompt = `
Sen bir Akademik Ortak YazarsÄ±n (Co-Author). Åu an "${topic}" baÅŸlÄ±klÄ± bir makale yazÄ±yoruz.
ÅU ANKÄ° GÃ–REV: Makalenin "${currentSection}" bÃ¶lÃ¼mÃ¼nÃ¼ yazmak veya revize etmek.
KURAL 1 (BAÄLAM): Sadece aÅŸaÄŸÄ±daki PDF kÃ¼tÃ¼phane iÃ§eriÄŸini kullan.
KURAL 2 (ATIF): APA 7 formatÄ±nda metin iÃ§i atÄ±f yap.
KURAL 3 (ETKÄ°LEÅÄ°M): Metni yazdÄ±ktan sonra, kullanÄ±cÄ±ya "Bu bÃ¶lÃ¼mÃ¼ onaylÄ±yor musunuz?" diye sor.
KURAL 4 (DÄ°L): TÃ¼rkÃ§e akademik dil kullan.

KullanÄ±cÄ± Geri Bildirimi: "${userFeedback}"

BAÄLAM:
"""
${context.substring(0, 80000)}
"""
    `;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: [{ role: 'user', parts: [{ text: prompt }] }],
            config: {
                temperature: 0.5,
                thinkingConfig: { thinkingBudget: 16384 }
            }
        });
        return response.text || "Yazma iÅŸlemi baÅŸarÄ±sÄ±z oldu.";
    } catch (error) {
        return handleError(error);
    }
};

/**
 * ğŸ™ï¸ AUDIO OVERVIEWâ„¢ (PODCAST) FUNCTIONS
 */

// 1. Script Generation
export const generatePodcastScript = async (context: string): Promise<string> => {
  const prompt = `
You are a specialized scriptwriter for "ScholarSphere Audio".
Generate a podcast script discussing the following academic content.

CHARACTERS:
1. HOST (Jane): Enthusiastic, curious, introduces topics, asks clarifying questions.
2. EXPERT (Joe): Analytical, slightly skeptical but knowledgeable, provides deep insights and citations.

Format the output exactly as a dialogue script:
Jane: [Line]
Joe: [Line]
Jane: [Line]

Keep the discussion engaging, covering key findings and methodology. 
LANGUAGE: TURKISH.

CONTENT TO DISCUSS:
"""
${context.substring(0, 50000)}
"""

Length: Approx 2 minutes of reading time (about 300 words).
`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });
    return response.text || "Script generation failed.";
  } catch (error) {
    return handleError(error);
  }
};

// 2. Audio Synthesis (Multi-Speaker)
export const generatePodcastAudio = async (script: string): Promise<Blob | null> => {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash-preview-tts",
            contents: [{ parts: [{ text: script }] }],
            config: {
                responseModalities: [Modality.AUDIO],
                speechConfig: {
                    multiSpeakerVoiceConfig: {
                        speakerVoiceConfigs: [
                            {
                                speaker: 'Jane',
                                voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Puck' } } // Enthusiastic
                            },
                            {
                                speaker: 'Joe',
                                voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Kore' } } // Deep/Calm
                            }
                        ]
                    }
                }
            }
        });

        const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
        if (base64Audio) {
             const audioBytes = base64ToUint8Array(base64Audio);
             const wavBytes = pcmToWav(audioBytes, 24000); // Model output is typically 24kHz
             return new Blob([wavBytes], { type: 'audio/wav' });
        }
        return null;
    } catch (error) {
        console.error("TTS Error", error);
        throw error;
    }
};

// Helper: Base64 to Uint8Array
function base64ToUint8Array(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// Helper: PCM to WAV converter
function pcmToWav(pcmData: Uint8Array, sampleRate: number): ArrayBuffer {
    const numChannels = 1; // Mono usually, unless stereo specified
    const bitsPerSample = 16;
    const byteRate = (sampleRate * numChannels * bitsPerSample) / 8;
    const blockAlign = (numChannels * bitsPerSample) / 8;
    const wavHeaderSize = 44;
    const dataSize = pcmData.length;
    const totalSize = wavHeaderSize + dataSize;
    
    const buffer = new ArrayBuffer(totalSize);
    const view = new DataView(buffer);
    
    // RIFF identifier
    writeString(view, 0, 'RIFF');
    // file length
    view.setUint32(4, 36 + dataSize, true);
    // RIFF type
    writeString(view, 8, 'WAVE');
    // format chunk identifier
    writeString(view, 12, 'fmt ');
    // format chunk length
    view.setUint32(16, 16, true);
    // sample format (raw)
    view.setUint16(20, 1, true);
    // channel count
    view.setUint16(22, numChannels, true);
    // sample rate
    view.setUint32(24, sampleRate, true);
    // byte rate (sample rate * block align)
    view.setUint32(28, byteRate, true);
    // block align (channel count * bytes per sample)
    view.setUint16(32, blockAlign, true);
    // bits per sample
    view.setUint16(34, bitsPerSample, true);
    // data chunk identifier
    writeString(view, 36, 'data');
    // data chunk length
    view.setUint32(40, dataSize, true);
    
    // Write PCM data
    const pcmView = new Uint8Array(buffer, 44);
    pcmView.set(pcmData);
    
    return buffer;
}

function writeString(view: DataView, offset: number, string: string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}
