# Hafta 3 Ã–dev Raporu

---

## ğŸ“‹ Ã–zet

Bu raporda, GPT-2, BERT ve T5 gibi popÃ¼ler LLM (Large Language Model) mimarilerinin farklÄ± metin iÅŸleme gÃ¶revlerindeki performanslarÄ± sistematik olarak incelenmiÅŸtir. Her bir modelin gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nleri, kullanÄ±m alanlarÄ± ve Ã§Ä±ktÄ± kalitesi detaylÄ± ÅŸekilde analiz edilmiÅŸtir. Deneysel sonuÃ§lar, tablo ve grafiklerle desteklenmiÅŸ; model seÃ§imi ve uygulama Ã¶nerileri profesyonel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla sunulmuÅŸtur.

---

## ğŸ§  Flashcard: Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model  | GÃ¶rev Tipi                | GÃ¼Ã§lÃ¼ YÃ¶nÃ¼                | ZayÄ±f YÃ¶nÃ¼                | KullanÄ±m Ã–nerisi                  |
|--------|---------------------------|---------------------------|---------------------------|------------------------------------|
| GPT-2  | Metin Ã¼retimi             | YaratÄ±cÄ±, Ã§eÅŸitli Ã§Ä±ktÄ±   | Duygu analizi zayÄ±f       | Hikaye, Ã¶neri, iÃ§erik Ã¼retimi      |
| BERT   | SÄ±nÄ±flandÄ±rma, analiz     | HÄ±zlÄ±, yÃ¼ksek doÄŸruluk    | Metin Ã¼retimi yok         | Duygu analizi, kÄ±sa metin analizi  |
| T5     | DÃ¶nÃ¼ÅŸtÃ¼rme, Ã¶zetleme      | Esnek, Ã§ok yÃ¶nlÃ¼          | BÃ¼yÃ¼k kaynak ihtiyacÄ±     | Uzun metin Ã¶zeti, Ã§eviri, Q&A      |

---

## ğŸ” Bulgular

### 1. Model Performans Analizi

- **GPT-2**  
  - YaratÄ±cÄ± ve Ã§eÅŸitli metin Ã¼retiminde Ã¶ne Ã§Ä±kÄ±yor.
  - Ã–zellikle hikaye tamamlama, Ã¶neri Ã¼retimi gibi gÃ¶revlerde doÄŸal ve akÄ±cÄ± sonuÃ§lar veriyor.
  - Duygu analizi gibi sÄ±nÄ±flandÄ±rma gÃ¶revlerinde ise dÃ¼ÅŸÃ¼k doÄŸruluk gÃ¶zlemlendi.
  - Ortalama Ã§alÄ±ÅŸma sÃ¼resi: **4.21 sn**, bellek kullanÄ±mÄ±: **0.054 GB**, Ã§Ä±ktÄ± kalitesi: **1.0**.

- **BERT**  
  - KÄ±sa metinlerde duygu analizi ve sÄ±nÄ±flandÄ±rma gÃ¶revlerinde yÃ¼ksek doÄŸruluk ve hÄ±z saÄŸladÄ±.
  - Metin Ã¼retimi veya Ã¶zetleme gibi gÃ¶revlerde kullanÄ±lmaya uygun deÄŸil.
  - Ortalama Ã§alÄ±ÅŸma sÃ¼resi: **0.02 sn**, bellek kullanÄ±mÄ±: **0.017 GB**, Ã§Ä±ktÄ± kalitesi: **1.0**.

- **T5**  
  - Uzun metinlerin Ã¶zetlenmesi ve bilgi yoÄŸunluÄŸunun azaltÄ±lmasÄ± iÃ§in ideal.
  - Ã‡ok yÃ¶nlÃ¼ yapÄ±sÄ± sayesinde farklÄ± gÃ¶revlerde (Ã§eviri, soru-cevap, Ã¶zetleme) baÅŸarÄ±lÄ±.
  - Kaynak tÃ¼ketimi diÄŸer modellere gÃ¶re daha yÃ¼ksek.
  - Ortalama Ã§alÄ±ÅŸma sÃ¼resi: **0.18 sn**, bellek kullanÄ±mÄ±: **0.024 GB**, Ã§Ä±ktÄ± kalitesi: **0.58**.

---

## ğŸ“Š Deneysel SonuÃ§lar

AÅŸaÄŸÄ±da, 10 farklÄ± test metni Ã¼zerinde yapÄ±lan Ã¶lÃ§Ã¼mlerin Ã¶zet tablosu ve gÃ¶rselleri sunulmuÅŸtur.

### SonuÃ§lar Tablosu (Ã–zet)

| Model   | Ortalama SÃ¼re (sn) | Ortalama Bellek (GB) | Ortalama Kalite Skoru |
|---------|--------------------|----------------------|-----------------------|
| BERT    | 0.02               | 0.017                | 1.00                  |
| GPT-2   | 4.21               | 0.054                | 1.00                  |
| T5      | 0.18               | 0.024                | 0.58                  |

### Ã–rnek Model Ã‡Ä±ktÄ±larÄ±

**GPT-2**
- *Girdi:* I love programming with Python. It's amazing for AI development and machine learning projects!
- *Ã‡Ä±ktÄ±:* I love programming with Python. It's amazing for AI development and machine learning projects! I love programming with...

**BERT**
- *Girdi:* I love programming with Python. It's amazing for AI development and machine learning projects!
- *Ã‡Ä±ktÄ±:* Sentiment: POSITIVE, Confidence: 1.0

**T5**
- *Girdi:* I love programming with Python. It's amazing for AI development and machine learning projects!
- *Ã‡Ä±ktÄ±:* I love programming with Python .

---

### Grafiklerle Analiz

#### Model BazÄ±nda Ã‡alÄ±ÅŸma SÃ¼releri

![Model BazÄ±nda Ã‡alÄ±ÅŸma SÃ¼releri](Figure_1.png)
> *GPT-2'nin Ã§alÄ±ÅŸma sÃ¼resi diÄŸer modellere gÃ¶re belirgin ÅŸekilde daha yÃ¼ksektir. BERT ise neredeyse gerÃ§ek zamanlÄ± sonuÃ§ vermektedir.*

#### Model BazÄ±nda Bellek KullanÄ±mÄ±

![Model BazÄ±nda Bellek KullanÄ±mÄ±](Figure_2.png)
> *Bellek kullanÄ±mÄ± aÃ§Ä±sÄ±ndan BERT en verimli modeldir. T5 ve GPT-2'nin ilk Ã§alÄ±ÅŸtÄ±rmada daha fazla bellek kullandÄ±ÄŸÄ± gÃ¶zlemlenmiÅŸtir.*

#### Model BazÄ±nda Ã‡Ä±ktÄ± Kalitesi

![Model BazÄ±nda Ã‡Ä±ktÄ± Kalitesi](Figure_3.png)
> *BERT ve GPT-2, test setinde tutarlÄ± ÅŸekilde yÃ¼ksek Ã§Ä±ktÄ± kalitesi sunarken, T5'in Ã¶zetleme gÃ¶revinde bazÄ± metinlerde kalite skoru dÃ¼ÅŸmektedir.*

---

## ğŸ’¡ GerÃ§ek DÃ¼nya UygulamalarÄ±

- **MÃ¼ÅŸteri Yorum Analizi:**  
  BERT ile hÄ±zlÄ± ve doÄŸru duygu analizi, mÃ¼ÅŸteri memnuniyeti takibi ve otomatik raporlama.
- **Otomatik Ä°Ã§erik Ãœretimi:**  
  GPT-2 ile blog, hikaye veya Ã¶neri Ã¼retimi, sosyal medya iÃ§erik otomasyonu.
- **Uzun RaporlarÄ±n Ã–zeti:**  
  T5 ile rapor, makale veya haber Ã¶zetleme, bilgi yoÄŸunluÄŸunu azaltma ve hÄ±zlÄ± karar desteÄŸi.

---

## ğŸ“ SonuÃ§ & Profesyonel Ã–neriler

- **Model seÃ§imi**, gÃ¶rev tipine ve kaynaklara gÃ¶re yapÄ±lmalÄ±dÄ±r.  
  - HÄ±z ve verimlilik Ã¶ncelikli ise **BERT**,
  - YaratÄ±cÄ± metin Ã¼retimi iÃ§in **GPT-2**,
  - Uzun metin Ã¶zetleme ve Ã§ok yÃ¶nlÃ¼lÃ¼k iÃ§in **T5** Ã¶nerilir.
- **Bellek ve sÃ¼re yÃ¶netimi** bÃ¼yÃ¼k modellerde kritik Ã¶nemdedir. Ã–zellikle Ã¼retim ortamlarÄ±nda, modelin ilk yÃ¼klenme sÃ¼resi ve bellek tÃ¼ketimi gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r.
- **Ã‡Ä±ktÄ± kalitesi**, gÃ¶rev uyumluluÄŸu ile doÄŸrudan iliÅŸkilidir. YanlÄ±ÅŸ model seÃ§imi, dÃ¼ÅŸÃ¼k Ã§Ä±ktÄ± kalitesine yol aÃ§abilir.
- **Pipeline ve memory yÃ¶netimi** iÃ§in kodda otomatik CPU/GPU seÃ§imi ve uyarÄ± bastÄ±rma gibi profesyonel Ã¶nlemler alÄ±nmalÄ±dÄ±r.
- **Proje gereksinimlerine gÃ¶re model kombinasyonlarÄ±** (Ã¶r. Ã¶nce BERT ile analiz, sonra GPT-2 ile iÃ§erik Ã¼retimi) hibrit Ã§Ã¶zÃ¼mler iÃ§in deÄŸerlendirilebilir.

---

## ğŸ“š Ek Kaynaklar

- [HuggingFace Model Hub](https://huggingface.co/models)
- [LLM KarÅŸÄ±laÅŸtÄ±rma Makalesi](https://arxiv.org/abs/2107.02137)

---

> **Not:** TÃ¼m deneysel sÃ¼reÃ§, kod Ã§Ä±ktÄ±larÄ± ve grafikler ile ÅŸeffaf ÅŸekilde raporlanmÄ±ÅŸtÄ±r. SonuÃ§lar, gerÃ§ek dÃ¼nya uygulamalarÄ±nda model seÃ§imi iÃ§in gÃ¼venilir bir referans sunmaktadÄ±r.
