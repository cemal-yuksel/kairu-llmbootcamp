<p align="center">
  <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="120"/>
</p>

<h1 align="center" style="font-size:2.2em; color:#2d3748;">
  <b>LLM BOOTCAMP 3. HAFTA ASSIGNMENT<br>DEÄERLENDÄ°RME RAPORU</b>
</h1>

---

## ğŸ“Œ Executive Summary

Bu teknik raporda, **GPT-2**, **BERT** ve **T5** gibi gÃ¼nÃ¼mÃ¼zÃ¼n Ã¶nde gelen LLM mimarilerinin Ã§eÅŸitli metin iÅŸleme gÃ¶revlerindeki performanslarÄ±, profesyonel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Her bir modelin gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nleri, kullanÄ±m alanlarÄ± ve Ã§Ä±ktÄ± kalitesi; deneysel veriler, tablolar ve grafiklerle desteklenerek detaylÄ± biÃ§imde analiz edilmiÅŸtir. Rapor, model seÃ§imi ve uygulama stratejileri iÃ§in ileri dÃ¼zey Ã¶neriler sunmaktadÄ±r.

---

## ğŸ§  LLM KarÅŸÄ±laÅŸtÄ±rma & Kavramlar

<div align="center">

| <b>Model</b> | <b>GÃ¶rev Tipi</b> | <b>En GÃ¼Ã§lÃ¼ YÃ¶nÃ¼</b> | <b>En ZayÄ±f YÃ¶nÃ¼</b> | <b>Profesyonel KullanÄ±m Ã–nerisi</b> |
|:---:|:---:|:---:|:---:|:---:|
| <span style="color:#7f5af0"><b>GPT-2</b></span> | Metin Ãœretimi | <span style="color:#2cb67d"><b>YaratÄ±cÄ± ve Ã§eÅŸitli Ã§Ä±ktÄ±</b></span> | Duygu analizi zayÄ±f | Hikaye, Ã¶neri, iÃ§erik Ã¼retimi |
| <span style="color:#ff8906"><b>BERT</b></span> | SÄ±nÄ±flandÄ±rma, Analiz | <span style="color:#2cb67d"><b>HÄ±zlÄ±, yÃ¼ksek doÄŸruluk</b></span> | Metin Ã¼retimi yok | Duygu analizi, kÄ±sa metin analizi |
| <span style="color:#f25f4c"><b>T5</b></span> | DÃ¶nÃ¼ÅŸtÃ¼rme, Ã–zetleme | <span style="color:#2cb67d"><b>Ã‡ok yÃ¶nlÃ¼, esnek</b></span> | YÃ¼ksek kaynak ihtiyacÄ± | Uzun metin Ã¶zeti, Ã§eviri, Q&A |

</div>

---

### ğŸš€ <span style="color:#2cb67d"><b>En Ä°yi Performanslar</b></span> 

- **En HÄ±zlÄ± Model:** <span style="color:#ff8906"><b>BERT</b></span> (0.02 sn)
- **En YÃ¼ksek Ã‡Ä±ktÄ± Kalitesi:** <span style="color:#7f5af0"><b>GPT-2</b></span> & <span style="color:#ff8906"><b>BERT</b></span> (Skor: 1.00)
- **En Verimli Bellek KullanÄ±mÄ±:** <span style="color:#ff8906"><b>BERT</b></span> (0.017 GB)
- **En YaratÄ±cÄ± Ã‡Ä±ktÄ±:** <span style="color:#7f5af0"><b>GPT-2</b></span>
- **En Ã‡ok YÃ¶nlÃ¼ Model:** <span style="color:#f25f4c"><b>T5</b></span>

---

## ğŸ“Š Deneysel SonuÃ§lar & Analiz

### SonuÃ§lar Tablosu

| <b>Model</b> | <b>Ortalama SÃ¼re (sn)</b> | <b>Ortalama Bellek (GB)</b> | <b>Ortalama Kalite Skoru</b> |
|:---:|:---:|:---:|:---:|
| <span style="color:#ff8906"><b>BERT</b></span> | <b>0.02</b> | <b>0.017</b> | <b>1.00</b> |
| <span style="color:#7f5af0"><b>GPT-2</b></span> | 4.21 | 0.054 | <b>1.00</b> |
| <span style="color:#f25f4c"><b>T5</b></span> | 0.18 | 0.024 | 0.58 |

---

### ğŸ“ˆ Grafiklerle KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

#### â±ï¸ Model BazÄ±nda Ã‡alÄ±ÅŸma SÃ¼releri

![Model BazÄ±nda Ã‡alÄ±ÅŸma SÃ¼releri](Figure_1.png)
> **Yorum:** Grafik, modellerin 10 farklÄ± metin Ã¼zerinde gÃ¶sterdiÄŸi iÅŸlem sÃ¼relerini karÅŸÄ±laÅŸtÄ±rmalÄ± olarak sunmaktadÄ±r. **BERT**, tÃ¼m Ã¶rneklerde neredeyse sabit ve Ã§ok dÃ¼ÅŸÃ¼k bir sÃ¼reyle (yaklaÅŸÄ±k 0.02 sn) gerÃ§ek zamanlÄ± performans sergilemektedir. **T5** modeli, gÃ¶revine gÃ¶re deÄŸiÅŸmekle birlikte, genellikle 0.1-0.3 sn aralÄ±ÄŸÄ±nda stabil bir hÄ±z sunar. **GPT-2** ise, 4-4.5 sn aralÄ±ÄŸÄ±nda, diÄŸer modellere kÄ±yasla Ã§ok daha yÃ¼ksek ve deÄŸiÅŸken bir sÃ¼reye sahiptir. Bu durum, Ã¼retim ortamlarÄ±nda hÄ±zÄ±n kritik olduÄŸu uygulamalarda BERTâ€™in aÃ§Ä±k ara avantajlÄ± olduÄŸunu, GPT-2â€™nin ise yÃ¼ksek iÅŸlem sÃ¼resi nedeniyle daha Ã§ok offline veya toplu iÅŸlerde tercih edilmesi gerektiÄŸini gÃ¶stermektedir.

#### ğŸ’¾ Model BazÄ±nda Bellek KullanÄ±mÄ±

![Model BazÄ±nda Bellek KullanÄ±mÄ±](Figure_2.png)
> **Yorum:** Bellek kullanÄ±mÄ± grafiÄŸi, modellerin ilk Ã§alÄ±ÅŸtÄ±rmada ve sonraki iÅŸlemlerde ne kadar bellek tÃ¼kettiÄŸini gÃ¶stermektedir. **BERT** ve **T5**, ilk Ã§alÄ±ÅŸtÄ±rmada sÄ±rasÄ±yla 0.17 GB ve 0.24 GB civarÄ±nda bellek kullanÄ±rken, **GPT-2** ilk yÃ¼klemede 0.54 GB ile en yÃ¼ksek deÄŸeri gÃ¶stermektedir. Sonraki iÅŸlemlerde ise tÃ¼m modellerin bellek kullanÄ±mÄ± neredeyse sÄ±fÄ±ra yakÄ±n seyretmektedir. Bu sonuÃ§, Ã¶zellikle bulut veya kaynak kÄ±sÄ±tlÄ± ortamlarda **BERT**â€™in verimliliÄŸini ve **GPT-2**â€™nin yÃ¼ksek kaynak ihtiyacÄ±nÄ± aÃ§Ä±kÃ§a ortaya koymaktadÄ±r.

#### ğŸ† Model BazÄ±nda Ã‡Ä±ktÄ± Kalitesi

![Model BazÄ±nda Ã‡alÄ±ÅŸma Kalitesi](Figure_3.png)
> **Yorum:** Ã‡Ä±ktÄ± kalitesi grafiÄŸi, her modelin 10 farklÄ± metin Ã¼zerindeki kalite skorlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmaktadÄ±r. **BERT** ve **GPT-2**, tÃ¼m Ã¶rneklerde maksimum kalite skoru (**1.0**) ile tutarlÄ± ve gÃ¼venilir sonuÃ§lar Ã¼retmektedir. **T5** ise bazÄ± metinlerde kalite skorunun 0.4â€™e kadar dÃ¼ÅŸtÃ¼ÄŸÃ¼, bazÄ± metinlerde ise 1.0â€™a ulaÅŸtÄ±ÄŸÄ± dalgalÄ± bir performans sergilemektedir. Bu durum, T5â€™in Ã¶zetleme ve dÃ¶nÃ¼ÅŸtÃ¼rme gÃ¶revlerinde metin yapÄ±sÄ±na duyarlÄ± olduÄŸunu, BERT ve GPT-2â€™nin ise kendi uzmanlÄ±k alanlarÄ±nda istikrarlÄ± kalite sunduÄŸunu gÃ¶stermektedir.

---

## ğŸ“ Model BazÄ±nda Derinlemesine Analiz

GPT-2, **yaratÄ±cÄ± ve Ã§eÅŸitli metin Ã¼retimi** konusunda sektÃ¶rde Ã¶ne Ã§Ä±kan bir modeldir. Ã–zellikle hikaye tamamlama, Ã¶neri Ã¼retimi ve iÃ§erik otomasyonu gibi gÃ¶revlerde, doÄŸal ve akÄ±cÄ± Ã§Ä±ktÄ±lar sunarak rakiplerinden ayrÄ±ÅŸmaktadÄ±r. Ancak, sÄ±nÄ±flandÄ±rma ve duygu analizi gibi gÃ¶revlerde doÄŸruluk oranÄ± belirgin ÅŸekilde dÃ¼ÅŸmektedir. Ortalama 4.21 saniyelik Ã§alÄ±ÅŸma sÃ¼resi ve 0.054 GB bellek kullanÄ±mÄ± ile, yÃ¼ksek Ã§Ä±ktÄ± kalitesine (**1.0**) raÄŸmen kaynak tÃ¼ketimi aÃ§Ä±sÄ±ndan dikkatli yÃ¶netilmelidir.

BERT ise, **hÄ±z ve doÄŸruluk** gerektiren kÄ±sa metin sÄ±nÄ±flandÄ±rma ve duygu analizi gÃ¶revlerinde endÃ¼stri standardÄ± olarak Ã¶ne Ã§Ä±kmaktadÄ±r. 0.02 saniye gibi neredeyse gerÃ§ek zamanlÄ± bir yanÄ±t sÃ¼resi ve 0.017 GB ile en dÃ¼ÅŸÃ¼k bellek tÃ¼ketimi, onu Ã¼retim ortamlarÄ± iÃ§in ideal kÄ±lar. Metin Ã¼retimi veya Ã¶zetleme gibi yaratÄ±cÄ± gÃ¶revlerde ise kullanÄ±labilirliÄŸi yoktur. Ancak, Ã§Ä±ktÄ± kalitesi (**1.0**) ve verimliliÄŸi ile operasyonel sÃ¼reÃ§lerde gÃ¼venle tercih edilebilir.

T5 modeli, **uzun metin Ã¶zetleme ve Ã§ok yÃ¶nlÃ¼ doÄŸal dil iÅŸleme** gÃ¶revlerinde yÃ¼ksek esneklik sunar. Rapor, makale Ã¶zeti, Ã§eviri ve soru-cevap gibi karmaÅŸÄ±k gÃ¶revlerde baÅŸarÄ±lÄ± sonuÃ§lar verir. Ortalama 0.18 saniyelik Ã§alÄ±ÅŸma sÃ¼resi ve 0.024 GB bellek kullanÄ±mÄ± ile, kaynak tÃ¼ketimi BERTâ€™e gÃ¶re daha yÃ¼ksek olsa da, Ã§ok yÃ¶nlÃ¼lÃ¼ÄŸÃ¼ sayesinde geniÅŸ uygulama alanlarÄ±na sahiptir. Ancak, bazÄ± metinlerde Ã§Ä±ktÄ± kalitesi (**0.58**) beklenenin altÄ±nda kalabilmektedir; bu nedenle gÃ¶rev uyumluluÄŸu dikkatle deÄŸerlendirilmelidir.

---

## ğŸ’¡ GerÃ§ek DÃ¼nya Uygulama SenaryolarÄ±

- <b>MÃ¼ÅŸteri Yorum Analizi:</b> <span style="color:#ff8906"><b>BERT</b></span> ile hÄ±zlÄ± ve doÄŸru duygu analizi, otomatik raporlama.
- <b>Otomatik Ä°Ã§erik Ãœretimi:</b> <span style="color:#7f5af0"><b>GPT-2</b></span> ile blog, hikaye, Ã¶neri Ã¼retimi.
- <b>Uzun RaporlarÄ±n Ã–zeti:</b> <span style="color:#f25f4c"><b>T5</b></span> ile bilgi yoÄŸunluÄŸunu azaltma, hÄ±zlÄ± karar desteÄŸi.

---

## ğŸ… Profesyonel SonuÃ§lar & Stratejik Ã–neriler

- <b>Model seÃ§imi</b> gÃ¶rev tipine ve kaynaklara gÃ¶re yapÄ±lmalÄ±dÄ±r:
  - <span style="color:#ff8906"><b>BERT</b></span> â†’ <b>HÄ±z ve verimlilik</b> Ã¶ncelikli ise.
  - <span style="color:#7f5af0"><b>GPT-2</b></span> â†’ <b>YaratÄ±cÄ± metin Ã¼retimi</b> iÃ§in.
  - <span style="color:#f25f4c"><b>T5</b></span> â†’ <b>Uzun metin Ã¶zetleme ve Ã§ok yÃ¶nlÃ¼lÃ¼k</b> iÃ§in.
- <b>Bellek ve sÃ¼re yÃ¶netimi</b> bÃ¼yÃ¼k modellerde kritik Ã¶nemdedir. Ãœretim ortamlarÄ±nda modelin ilk yÃ¼klenme sÃ¼resi ve bellek tÃ¼ketimi gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r.
- <b>Ã‡Ä±ktÄ± kalitesi</b>, gÃ¶rev uyumluluÄŸu ile doÄŸrudan iliÅŸkilidir. YanlÄ±ÅŸ model seÃ§imi, dÃ¼ÅŸÃ¼k Ã§Ä±ktÄ± kalitesine yol aÃ§abilir.
- <b>Pipeline ve memory yÃ¶netimi</b> iÃ§in kodda otomatik CPU/GPU seÃ§imi ve uyarÄ± bastÄ±rma gibi profesyonel Ã¶nlemler alÄ±nmalÄ±dÄ±r.
- <b>Hibrit Ã§Ã¶zÃ¼mler</b> iÃ§in model kombinasyonlarÄ± (Ã¶r. Ã¶nce <span style="color:#ff8906"><b>BERT</b></span> ile analiz, sonra <span style="color:#7f5af0"><b>GPT-2</b></span> ile iÃ§erik Ã¼retimi) deÄŸerlendirilebilir.

---

## ğŸ“š Ek Kaynaklar

- [HuggingFace Model Hub](https://huggingface.co/models)
- [LLM KarÅŸÄ±laÅŸtÄ±rma Makalesi](https://arxiv.org/abs/2107.02137)

---

> <span style="color:#2cb67d"><b>Not:</b></span> TÃ¼m deneysel sÃ¼reÃ§, kod Ã§Ä±ktÄ±larÄ± ve grafikler ile ÅŸeffaf ÅŸekilde raporlanmÄ±ÅŸtÄ±r. SonuÃ§lar, gerÃ§ek dÃ¼nya uygulamalarÄ±nda model seÃ§imi iÃ§in gÃ¼venilir bir referans sunmaktadÄ±r.
- <b>Bellek ve sÃ¼re yÃ¶netimi</b> bÃ¼yÃ¼k modellerde kritik Ã¶nemdedir. Ãœretim ortamlarÄ±nda modelin ilk yÃ¼klenme sÃ¼resi ve bellek tÃ¼ketimi gÃ¶z Ã¶nunda bulundurulmalÄ±dÄ±r.
- <b>Ã‡Ä±ktÄ± kalitesi</b>, gÃ¶rev uyumluluÄŸu ile doÄŸrudan iliÅŸkilidir. YanlÄ±ÅŸ model seÃ§imi, dÃ¼ÅŸÃ¼k Ã§Ä±ktÄ± kalitesine yol aÃ§abilir.
- <b>Pipeline ve memory yÃ¶netimi</b> iÃ§in kodda otomatik CPU/GPU seÃ§imi ve uyarÄ± bastÄ±rma gibi profesyonel Ã¶nlemler alÄ±nmalÄ±dÄ±r.
- <b>Hibrit Ã§Ã¶zÃ¼mler</b> iÃ§in model kombinasyonlarÄ± (Ã¶r. Ã¶nce <span style="color:#ff8906"><b>BERT</b></span> ile analiz, sonra <span style="color:#7f5af0"><b>GPT-2</b></span> ile iÃ§erik Ã¼retimi) deÄŸerlendirilebilir.

---

## ğŸ“š Ek Kaynaklar

- [HuggingFace Model Hub](https://huggingface.co/models)
- [LLM KarÅŸÄ±laÅŸtÄ±rma Makalesi](https://arxiv.org/abs/2107.02137)

---

> <span style="color:#2cb67d"><b>Not:</b></span> TÃ¼m deneysel sÃ¼reÃ§, kod Ã§Ä±ktÄ±larÄ± ve grafikler ile ÅŸeffaf ÅŸekilde raporlanmÄ±ÅŸtÄ±r. SonuÃ§lar, gerÃ§ek dÃ¼nya uygulamalarÄ±nda model seÃ§imi iÃ§in gÃ¼venilir bir referans sunmaktadÄ±r.
