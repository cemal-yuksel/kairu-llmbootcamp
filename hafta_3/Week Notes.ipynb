{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0da164",
   "metadata": {},
   "source": [
    "# 🚀 **Hafta 3: Transformers Temelleri ve Optimizasyon**\n",
    "\n",
    "<div style=\"background:#eaf6fb; border-left:6px solid #2980B9; padding:16px; border-radius:8px;\">\n",
    "<span style=\"font-size:1.2em; font-weight:bold; color:#2980B9;\">Bu notlar, <span style=\"color:#C0392B;\">Hugging Face Transformers dünyasını, temel kavramları ve üretim kalitesinde NLP için optimizasyon tekniklerini </span><span style=\"color:#229954;\">adım adım</span> öğretmek için hazırlanmıştır.</span>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2cb7f",
   "metadata": {},
   "source": [
    "## 📅 İçindekiler\n",
    "1. [Transformers Nedir?](#transformers-nedir)\n",
    "2. [AutoTokenizer & AutoModel: Temel Kavramlar](#autotokenizer-automodel)\n",
    "3. [Pipeline: Tek Satırda NLP](#pipeline)\n",
    "4. [Transformer Mimarileri: GPT, BERT, T5](#mimariler)\n",
    "5. [Cihaz ve Model Optimizasyonu](#optimizasyon)\n",
    "6. [Performans Ölçümü ve Benchmarking](#benchmark)\n",
    "7. [En İyi Uygulamalar](#bestpractices)\n",
    "8. [Ek Kaynaklar](#resources)\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "🔔 <b>İpucu:</b> <span style=\"color:#b7950b;\">Her bölümde önemli noktalar <b>kalın</b>, renkli ve ikonlarla vurgulanmıştır!</span>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0cd41",
   "metadata": {},
   "source": [
    "## 1. Transformers Nedir?\n",
    "\n",
    "**Transformers**, günümüzün en güçlü doğal dil işleme (NLP) modellerinin temelini oluşturan bir mimaridir. 2017'de \"Attention is All You Need\" makalesiyle tanıtılmıştır.\n",
    "\n",
    "**Avantajları:**\n",
    "- Uzun metinlerde bağlamı çok iyi anlar.\n",
    "- Paralel işlemeye uygundur (hızlıdır).\n",
    "- Farklı görevler için kolayca uyarlanabilir.\n",
    "\n",
    "**Hugging Face Transformers** kütüphanesi, bu mimarinin binlerce hazır modelini kolayca kullanmanızı sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b8c69",
   "metadata": {},
   "source": [
    "## 2. AutoTokenizer & AutoModel: Temel Kavramlar\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #229954; padding:12px; border-radius:8px;\">\n",
    "🔑 <b style=\"color:#229954;\">AutoTokenizer</b> ve <b style=\"color:#2980B9;\">AutoModel</b> <b>birlikte</b> veya <b>ayrı ayrı</b> kullanılabilir. Her birinin rolü farklıdır ve birlikte kullanıldığında <span style=\"color:#CA6F1E;\">tam bir inference pipeline</span> kurarsınız.\n",
    "</div>\n",
    "\n",
    "### 🔹 <span style=\"color:#229954;\">AutoTokenizer</span> Nedir?\n",
    "- <b>Görev:</b> Metni, modelin anlayacağı <b style=\"color:#CA6F1E;\">tokenlara</b> (sayılara) çevirir.\n",
    "- <b>Örnek:</b> \"Merhaba dünya\" → [101, 1234, 4567, 102]\n",
    "- <b>Ekstra:</b> Tokenizer, <b>decode</b> işlemiyle sayıları tekrar metne çevirebilir.\n",
    "\n",
    "### 🔹 <span style=\"color:#2980B9;\">AutoModel</span> Nedir?\n",
    "- <b>Görev:</b> Tokenları alır, <b style=\"color:#8E44AD;\">modelin matematiksel katmanlarından</b> geçirir ve çıktı üretir.\n",
    "- <b>Çıktı:</b> Genellikle <b>hidden states</b> (gizli temsiller) veya görev özelinde başka çıktılar.\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "🧩 <b>Farkları:</b><br>\n",
    "<b style=\"color:#229954;\">AutoTokenizer</b> sadece <b>metin ↔ token</b> dönüşümü yapar.<br>\n",
    "<b style=\"color:#2980B9;\">AutoModel</b> ise <b>token ↔ çıktı</b> dönüşümünü sağlar.<br>\n",
    "<b>Birlikte kullanınca:</b> <span style=\"color:#CA6F1E;\">Ham metinden model çıktısına tam yolculuk</span> elde edilir!\n",
    "</div>\n",
    "\n",
    "### 👩‍💻 <span style=\"color:#229954;\">AutoTokenizer</span> ve <span style=\"color:#2980B9;\">AutoModel</span> ile Adım Adım\n",
    "\n",
    "<div style=\"background:#e8daef; border-left:6px solid #8E44AD; padding:10px; border-radius:8px;\">\n",
    "📝 <b>Flashcard:</b> <b>AutoTokenizer</b> olmadan <b>AutoModel</b> kullanırsanız, modele <b>doğrudan metin</b> veremezsiniz! Model <b>sayısal token</b> ister.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35683459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Metni tokenlara çevir (encode)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(\"Transformers harika!\", return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "\n",
    "# 2️⃣ Tokenları modele ver, çıktı al\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)  # (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "# 3️⃣ (İsteğe bağlı) Tokenları tekrar metne çevir (decode)\n",
    "decoded = tokenizer.decode(inputs['input_ids'][0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1e71b",
   "metadata": {},
   "source": [
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "💡 <b>Önemli:</b> <b>AutoTokenizer</b> ve <b>AutoModel</b> <span style=\"color:#C0392B;\">her zaman aynı model adıyla</span> çağrılmalı! (örn. \"bert-base-uncased\")\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary><b>🎓 Sıkça Sorulan: Sadece AutoTokenizer veya sadece AutoModel kullanılır mı?</b></summary>\n",
    "<ul>\n",
    "<li><b>Sadece AutoTokenizer:</b> Metni tokenlara çevirip başka bir yerde (ör. veri ön işleme) kullanabilirsiniz.</li>\n",
    "<li><b>Sadece AutoModel:</b> Tokenları başka bir tokenizer ile hazırladıysanız veya ileri düzey kullanımda mümkündür.</li>\n",
    "<li><b>En yaygın ve güvenli yol:</b> <b>İkisini birlikte</b> kullanmak!</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "🟢 <b>Özet:</b> <b>AutoTokenizer</b> = <span style=\"color:#CA6F1E;\">metin → token</span> <br>\n",
    "<b>AutoModel</b> = <span style=\"color:#CA6F1E;\">token → çıktı</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5decc",
   "metadata": {},
   "source": [
    "## 3. Pipeline: Tek Satırda NLP\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #CA6F1E; padding:10px; border-radius:8px;\">\n",
    "⚡ <b>Pipeline</b> ile <b>AutoTokenizer</b> ve <b>AutoModel</b> arka planda otomatik olarak eşleştirilir.<br>\n",
    "Sadece <b>görev adını</b> ve <b>modeli</b> belirtmeniz yeterli!\n",
    "</div>\n",
    "\n",
    "### 👩‍💻 <span style=\"color:#CA6F1E;\">Pipeline</span> ile Duygu Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
    "print(nlp(\"Transformers çok güçlü!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4c402",
   "metadata": {},
   "source": [
    "**Açıklama:**\n",
    "- Sadece görev adını ve modeli belirtmeniz yeterli.\n",
    "- Model ve tokenizer otomatik yüklenir.\n",
    "- Sonuç: Duygu analizi sonucu (pozitif/negatif) gelir.\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "🎯 <b>Avantaj:</b> <b>Pipeline</b> ile <span style=\"color:#229954;\">AutoTokenizer</span> ve <span style=\"color:#2980B9;\">AutoModel</span> kullanımı <b>tek satıra</b> iner. Hızlı prototipleme ve test için idealdir!\n",
    "</div>\n",
    "\n",
    "> <b>Pipeline ile:</b> Metin sınıflandırma, özetleme, çeviri, soru-cevap gibi birçok NLP görevini kolayca yapabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79056b35",
   "metadata": {},
   "source": [
    "## 4. Transformer Mimarileri: GPT, BERT, T5\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "🔬 <b>Her mimarinin kendine özgü avantajları ve kullanım alanları vardır.</b>\n",
    "</div>\n",
    "\n",
    "| <span style=\"color:#2980B9;\">Model</span>  | <span style=\"color:#CA6F1E;\">Mimari</span>         | <span style=\"color:#229954;\">Güçlü Yönler</span>           | <span style=\"color:#C0392B;\">Kullanım Alanları</span>                 |\n",
    "|--------|----------------|------------------------|-----------------------------------|\n",
    "| <b>GPT</b>    | Decoder-only   | Uzun metin üretimi     | Yaratıcı yazım, sohbet botları    |\n",
    "| <b>BERT</b>   | Encoder-only   | Anlam çıkarma, analiz  | Sınıflandırma, NER, Soru-Cevap    |\n",
    "| <b>T5</b>     | Encoder-Decoder| Her şey text-to-text   | Çeviri, özetleme, çoklu görevler  |\n",
    "\n",
    "<div style=\"background:#e8daef; border-left:6px solid #8E44AD; padding:10px; border-radius:8px;\">\n",
    "🧠 <b>Flashcard:</b> <b>GPT</b> üretkenlikte, <b>BERT</b> anlamada, <b>T5</b> ise çoklu görevlerde üstündür.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675e3c",
   "metadata": {},
   "source": [
    "## 5. Cihaz ve Model Optimizasyonu\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "⚙️ <b>Optimizasyon</b> ile <span style=\"color:#229954;\">hız</span>, <span style=\"color:#C0392B;\">verimlilik</span> ve <span style=\"color:#2980B9;\">düşük maliyet</span> elde edilir.\n",
    "</div>\n",
    "\n",
    "### 👩‍💻 Temel Kod Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v.to(device) for k, v in inputs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef45c8",
   "metadata": {},
   "source": [
    "**Açıklama:**\n",
    "- Model ve veriler uygun cihaza taşınır.\n",
    "- `torch.no_grad()` ile gereksiz hesaplamalar engellenir (daha hızlı ve az bellek kullanır).\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "💡 <b>İpucu:</b> <b>Quantization</b> (8-bit, 4-bit) ve <b>batch processing</b> ile büyük modelleri bile düşük donanımda hızlıca çalıştırabilirsiniz!\n",
    "</div>\n",
    "\n",
    "> **Not:** Quantization ve batch processing ile ilgili ileri teknikler için Hugging Face ve PyTorch dökümantasyonuna bakabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785b131",
   "metadata": {},
   "source": [
    "## 6. Performans Ölçümü ve Benchmarking\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #2980B9; padding:10px; border-radius:8px;\">\n",
    "⏱️ <b>Performans ölçümü</b> ile <span style=\"color:#C0392B;\">en hızlı ve verimli</span> pipeline'ı bulabilirsiniz.\n",
    "</div>\n",
    "\n",
    "### 👩‍💻 Basit Ölçüm Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6db0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "_ = nlp([\"Test cümlesi\"] * 32)\n",
    "print(\"Süre:\", time.time() - start, \"saniye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10a45b",
   "metadata": {},
   "source": [
    "**Açıklama:**\n",
    "- 32 örnek için inference süresi ölçülür.\n",
    "- Batch size ve cihaz değiştikçe bu süre değişir.\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "📊 <b>Önemli:</b> <b>Inference süresi</b>, <b>memory kullanımı</b> ve <b>throughput</b> üretim ortamında kritik metriklerdir!\n",
    "</div>\n",
    "\n",
    "> **İpucu:** Daha detaylı ölçümler için `psutil`, `torch.cuda.memory_allocated()` gibi araçlar kullanılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ef168",
   "metadata": {},
   "source": [
    "## 7. En İyi Uygulamalar (Best Practices)\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "✅ <b>Her zaman</b> <b>torch.no_grad()</b> ile inference yapın, <b>cihazı</b> otomatik seçin ve <b>memory leak</b> riskine karşı temizlik yapın!\n",
    "</div>\n",
    "\n",
    "### 🔹 Performans Optimizasyonu\n",
    "```python\n",
    "# ✅ İyi\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# ❌ Kötü\n",
    "outputs = model(**inputs)  # Gradient hesaplanır\n",
    "```\n",
    "\n",
    "### 🔹 Device Yönetimi\n",
    "```python\n",
    "# ✅ İyi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# ❌ Kötü\n",
    "model = model.to(\"cuda\")  # CUDA olmayabilir\n",
    "```\n",
    "\n",
    "### 🔹 Memory Yönetimi\n",
    "```python\n",
    "# ✅ İyi\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "\n",
    "# ❌ Kötü\n",
    "# Memory leak'e sebep olabilir\n",
    "```\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "🟠 <b>Flashcard:</b> <b>Pipeline</b> ile <b>AutoTokenizer</b> ve <b>AutoModel</b> arka planda otomatik yönetilir. <b>Manuel kullanımda</b> ise cihaz ve memory yönetimi sizin sorumluluğunuzdadır!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d684e7f",
   "metadata": {},
   "source": [
    "## 8. Ek Kaynaklar\n",
    "\n",
    "- <span style=\"color:#2980B9;\">[Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/)</span>\n",
    "- <span style=\"color:#229954;\">[PyTorch Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)</span>\n",
    "- <span style=\"color:#C0392B;\">[BERT Paper (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)</span>\n",
    "- <span style=\"color:#CA6F1E;\">[GPT Paper (Radford et al., 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)</span>\n",
    "- <span style=\"color:#8E44AD;\">[T5 Paper (Raffel et al., 2019)](https://arxiv.org/abs/1910.10683)</span>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\" style=\"font-size:1.2em; background:#f4f8fb; border-radius:8px; padding:16px; border:2px solid #CA6F1E;\">\n",
    "  <b>🌟 <span style=\"color:#CA6F1E;\">Transformers ile optimize pipeline</span>, <span style=\"color:#229954;\">üretim kalitesinde NLP'nin anahtarıdır!</span> 🌟</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
