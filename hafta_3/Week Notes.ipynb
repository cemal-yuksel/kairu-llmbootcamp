{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0da164",
   "metadata": {},
   "source": [
    "# ğŸš€ **Hafta 3: Transformers Temelleri ve Optimizasyon**\n",
    "\n",
    "<div style=\"background:#eaf6fb; border-left:6px solid #2980B9; padding:16px; border-radius:8px;\">\n",
    "<span style=\"font-size:1.2em; font-weight:bold; color:#2980B9;\">Bu notlar, <span style=\"color:#C0392B;\">Hugging Face Transformers dÃ¼nyasÄ±nÄ±, temel kavramlarÄ± ve Ã¼retim kalitesinde NLP iÃ§in optimizasyon tekniklerini </span><span style=\"color:#229954;\">adÄ±m adÄ±m</span> Ã¶ÄŸretmek iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.</span>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2cb7f",
   "metadata": {},
   "source": [
    "## ğŸ“… Ä°Ã§indekiler\n",
    "1. [Transformers Nedir?](#transformers-nedir)\n",
    "2. [AutoTokenizer & AutoModel: Temel Kavramlar](#autotokenizer-automodel)\n",
    "3. [Pipeline: Tek SatÄ±rda NLP](#pipeline)\n",
    "4. [Transformer Mimarileri: GPT, BERT, T5](#mimariler)\n",
    "5. [Cihaz ve Model Optimizasyonu](#optimizasyon)\n",
    "6. [Performans Ã–lÃ§Ã¼mÃ¼ ve Benchmarking](#benchmark)\n",
    "7. [En Ä°yi Uygulamalar](#bestpractices)\n",
    "8. [Ek Kaynaklar](#resources)\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "ğŸ”” <b>Ä°pucu:</b> <span style=\"color:#b7950b;\">Her bÃ¶lÃ¼mde Ã¶nemli noktalar <b>kalÄ±n</b>, renkli ve ikonlarla vurgulanmÄ±ÅŸtÄ±r!</span>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0cd41",
   "metadata": {},
   "source": [
    "## 1. Transformers Nedir?\n",
    "\n",
    "**Transformers**, gÃ¼nÃ¼mÃ¼zÃ¼n en gÃ¼Ã§lÃ¼ doÄŸal dil iÅŸleme (NLP) modellerinin temelini oluÅŸturan bir mimaridir. 2017'de \"Attention is All You Need\" makalesiyle tanÄ±tÄ±lmÄ±ÅŸtÄ±r.\n",
    "\n",
    "**AvantajlarÄ±:**\n",
    "- Uzun metinlerde baÄŸlamÄ± Ã§ok iyi anlar.\n",
    "- Paralel iÅŸlemeye uygundur (hÄ±zlÄ±dÄ±r).\n",
    "- FarklÄ± gÃ¶revler iÃ§in kolayca uyarlanabilir.\n",
    "\n",
    "**Hugging Face Transformers** kÃ¼tÃ¼phanesi, bu mimarinin binlerce hazÄ±r modelini kolayca kullanmanÄ±zÄ± saÄŸlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b8c69",
   "metadata": {},
   "source": [
    "## 2. AutoTokenizer & AutoModel: Temel Kavramlar\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #229954; padding:12px; border-radius:8px;\">\n",
    "ğŸ”‘ <b style=\"color:#229954;\">AutoTokenizer</b> ve <b style=\"color:#2980B9;\">AutoModel</b> <b>birlikte</b> veya <b>ayrÄ± ayrÄ±</b> kullanÄ±labilir. Her birinin rolÃ¼ farklÄ±dÄ±r ve birlikte kullanÄ±ldÄ±ÄŸÄ±nda <span style=\"color:#CA6F1E;\">tam bir inference pipeline</span> kurarsÄ±nÄ±z.\n",
    "</div>\n",
    "\n",
    "### ğŸ”¹ <span style=\"color:#229954;\">AutoTokenizer</span> Nedir?\n",
    "- <b>GÃ¶rev:</b> Metni, modelin anlayacaÄŸÄ± <b style=\"color:#CA6F1E;\">tokenlara</b> (sayÄ±lara) Ã§evirir.\n",
    "- <b>Ã–rnek:</b> \"Merhaba dÃ¼nya\" â†’ [101, 1234, 4567, 102]\n",
    "- <b>Ekstra:</b> Tokenizer, <b>decode</b> iÅŸlemiyle sayÄ±larÄ± tekrar metne Ã§evirebilir.\n",
    "\n",
    "### ğŸ”¹ <span style=\"color:#2980B9;\">AutoModel</span> Nedir?\n",
    "- <b>GÃ¶rev:</b> TokenlarÄ± alÄ±r, <b style=\"color:#8E44AD;\">modelin matematiksel katmanlarÄ±ndan</b> geÃ§irir ve Ã§Ä±ktÄ± Ã¼retir.\n",
    "- <b>Ã‡Ä±ktÄ±:</b> Genellikle <b>hidden states</b> (gizli temsiller) veya gÃ¶rev Ã¶zelinde baÅŸka Ã§Ä±ktÄ±lar.\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "ğŸ§© <b>FarklarÄ±:</b><br>\n",
    "<b style=\"color:#229954;\">AutoTokenizer</b> sadece <b>metin â†” token</b> dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapar.<br>\n",
    "<b style=\"color:#2980B9;\">AutoModel</b> ise <b>token â†” Ã§Ä±ktÄ±</b> dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ saÄŸlar.<br>\n",
    "<b>Birlikte kullanÄ±nca:</b> <span style=\"color:#CA6F1E;\">Ham metinden model Ã§Ä±ktÄ±sÄ±na tam yolculuk</span> elde edilir!\n",
    "</div>\n",
    "\n",
    "### ğŸ‘©â€ğŸ’» <span style=\"color:#229954;\">AutoTokenizer</span> ve <span style=\"color:#2980B9;\">AutoModel</span> ile AdÄ±m AdÄ±m\n",
    "\n",
    "<div style=\"background:#e8daef; border-left:6px solid #8E44AD; padding:10px; border-radius:8px;\">\n",
    "ğŸ“ <b>Flashcard:</b> <b>AutoTokenizer</b> olmadan <b>AutoModel</b> kullanÄ±rsanÄ±z, modele <b>doÄŸrudan metin</b> veremezsiniz! Model <b>sayÄ±sal token</b> ister.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35683459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ Metni tokenlara Ã§evir (encode)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(\"Transformers harika!\", return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "\n",
    "# 2ï¸âƒ£ TokenlarÄ± modele ver, Ã§Ä±ktÄ± al\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)  # (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "# 3ï¸âƒ£ (Ä°steÄŸe baÄŸlÄ±) TokenlarÄ± tekrar metne Ã§evir (decode)\n",
    "decoded = tokenizer.decode(inputs['input_ids'][0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1e71b",
   "metadata": {},
   "source": [
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "ğŸ’¡ <b>Ã–nemli:</b> <b>AutoTokenizer</b> ve <b>AutoModel</b> <span style=\"color:#C0392B;\">her zaman aynÄ± model adÄ±yla</span> Ã§aÄŸrÄ±lmalÄ±! (Ã¶rn. \"bert-base-uncased\")\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "<summary><b>ğŸ“ SÄ±kÃ§a Sorulan: Sadece AutoTokenizer veya sadece AutoModel kullanÄ±lÄ±r mÄ±?</b></summary>\n",
    "<ul>\n",
    "<li><b>Sadece AutoTokenizer:</b> Metni tokenlara Ã§evirip baÅŸka bir yerde (Ã¶r. veri Ã¶n iÅŸleme) kullanabilirsiniz.</li>\n",
    "<li><b>Sadece AutoModel:</b> TokenlarÄ± baÅŸka bir tokenizer ile hazÄ±rladÄ±ysanÄ±z veya ileri dÃ¼zey kullanÄ±mda mÃ¼mkÃ¼ndÃ¼r.</li>\n",
    "<li><b>En yaygÄ±n ve gÃ¼venli yol:</b> <b>Ä°kisini birlikte</b> kullanmak!</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "ğŸŸ¢ <b>Ã–zet:</b> <b>AutoTokenizer</b> = <span style=\"color:#CA6F1E;\">metin â†’ token</span> <br>\n",
    "<b>AutoModel</b> = <span style=\"color:#CA6F1E;\">token â†’ Ã§Ä±ktÄ±</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5decc",
   "metadata": {},
   "source": [
    "## 3. Pipeline: Tek SatÄ±rda NLP\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #CA6F1E; padding:10px; border-radius:8px;\">\n",
    "âš¡ <b>Pipeline</b> ile <b>AutoTokenizer</b> ve <b>AutoModel</b> arka planda otomatik olarak eÅŸleÅŸtirilir.<br>\n",
    "Sadece <b>gÃ¶rev adÄ±nÄ±</b> ve <b>modeli</b> belirtmeniz yeterli!\n",
    "</div>\n",
    "\n",
    "### ğŸ‘©â€ğŸ’» <span style=\"color:#CA6F1E;\">Pipeline</span> ile Duygu Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
    "print(nlp(\"Transformers Ã§ok gÃ¼Ã§lÃ¼!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4c402",
   "metadata": {},
   "source": [
    "**AÃ§Ä±klama:**\n",
    "- Sadece gÃ¶rev adÄ±nÄ± ve modeli belirtmeniz yeterli.\n",
    "- Model ve tokenizer otomatik yÃ¼klenir.\n",
    "- SonuÃ§: Duygu analizi sonucu (pozitif/negatif) gelir.\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "ğŸ¯ <b>Avantaj:</b> <b>Pipeline</b> ile <span style=\"color:#229954;\">AutoTokenizer</span> ve <span style=\"color:#2980B9;\">AutoModel</span> kullanÄ±mÄ± <b>tek satÄ±ra</b> iner. HÄ±zlÄ± prototipleme ve test iÃ§in idealdir!\n",
    "</div>\n",
    "\n",
    "> <b>Pipeline ile:</b> Metin sÄ±nÄ±flandÄ±rma, Ã¶zetleme, Ã§eviri, soru-cevap gibi birÃ§ok NLP gÃ¶revini kolayca yapabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79056b35",
   "metadata": {},
   "source": [
    "## 4. Transformer Mimarileri: GPT, BERT, T5\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "ğŸ”¬ <b>Her mimarinin kendine Ã¶zgÃ¼ avantajlarÄ± ve kullanÄ±m alanlarÄ± vardÄ±r.</b>\n",
    "</div>\n",
    "\n",
    "| <span style=\"color:#2980B9;\">Model</span>  | <span style=\"color:#CA6F1E;\">Mimari</span>         | <span style=\"color:#229954;\">GÃ¼Ã§lÃ¼ YÃ¶nler</span>           | <span style=\"color:#C0392B;\">KullanÄ±m AlanlarÄ±</span>                 |\n",
    "|--------|----------------|------------------------|-----------------------------------|\n",
    "| <b>GPT</b>    | Decoder-only   | Uzun metin Ã¼retimi     | YaratÄ±cÄ± yazÄ±m, sohbet botlarÄ±    |\n",
    "| <b>BERT</b>   | Encoder-only   | Anlam Ã§Ä±karma, analiz  | SÄ±nÄ±flandÄ±rma, NER, Soru-Cevap    |\n",
    "| <b>T5</b>     | Encoder-Decoder| Her ÅŸey text-to-text   | Ã‡eviri, Ã¶zetleme, Ã§oklu gÃ¶revler  |\n",
    "\n",
    "<div style=\"background:#e8daef; border-left:6px solid #8E44AD; padding:10px; border-radius:8px;\">\n",
    "ğŸ§  <b>Flashcard:</b> <b>GPT</b> Ã¼retkenlikte, <b>BERT</b> anlamada, <b>T5</b> ise Ã§oklu gÃ¶revlerde Ã¼stÃ¼ndÃ¼r.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e675e3c",
   "metadata": {},
   "source": [
    "## 5. Cihaz ve Model Optimizasyonu\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "âš™ï¸ <b>Optimizasyon</b> ile <span style=\"color:#229954;\">hÄ±z</span>, <span style=\"color:#C0392B;\">verimlilik</span> ve <span style=\"color:#2980B9;\">dÃ¼ÅŸÃ¼k maliyet</span> elde edilir.\n",
    "</div>\n",
    "\n",
    "### ğŸ‘©â€ğŸ’» Temel Kod Ã–rneÄŸi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v.to(device) for k, v in inputs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef45c8",
   "metadata": {},
   "source": [
    "**AÃ§Ä±klama:**\n",
    "- Model ve veriler uygun cihaza taÅŸÄ±nÄ±r.\n",
    "- `torch.no_grad()` ile gereksiz hesaplamalar engellenir (daha hÄ±zlÄ± ve az bellek kullanÄ±r).\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "ğŸ’¡ <b>Ä°pucu:</b> <b>Quantization</b> (8-bit, 4-bit) ve <b>batch processing</b> ile bÃ¼yÃ¼k modelleri bile dÃ¼ÅŸÃ¼k donanÄ±mda hÄ±zlÄ±ca Ã§alÄ±ÅŸtÄ±rabilirsiniz!\n",
    "</div>\n",
    "\n",
    "> **Not:** Quantization ve batch processing ile ilgili ileri teknikler iÃ§in Hugging Face ve PyTorch dÃ¶kÃ¼mantasyonuna bakabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785b131",
   "metadata": {},
   "source": [
    "## 6. Performans Ã–lÃ§Ã¼mÃ¼ ve Benchmarking\n",
    "\n",
    "<div style=\"background:#f4f8fb; border-left:6px solid #2980B9; padding:10px; border-radius:8px;\">\n",
    "â±ï¸ <b>Performans Ã¶lÃ§Ã¼mÃ¼</b> ile <span style=\"color:#C0392B;\">en hÄ±zlÄ± ve verimli</span> pipeline'Ä± bulabilirsiniz.\n",
    "</div>\n",
    "\n",
    "### ğŸ‘©â€ğŸ’» Basit Ã–lÃ§Ã¼m Ã–rneÄŸi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6db0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "_ = nlp([\"Test cÃ¼mlesi\"] * 32)\n",
    "print(\"SÃ¼re:\", time.time() - start, \"saniye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10a45b",
   "metadata": {},
   "source": [
    "**AÃ§Ä±klama:**\n",
    "- 32 Ã¶rnek iÃ§in inference sÃ¼resi Ã¶lÃ§Ã¼lÃ¼r.\n",
    "- Batch size ve cihaz deÄŸiÅŸtikÃ§e bu sÃ¼re deÄŸiÅŸir.\n",
    "\n",
    "<div style=\"background:#f9e79f; border-left:6px solid #b7950b; padding:10px; border-radius:8px;\">\n",
    "ğŸ“Š <b>Ã–nemli:</b> <b>Inference sÃ¼resi</b>, <b>memory kullanÄ±mÄ±</b> ve <b>throughput</b> Ã¼retim ortamÄ±nda kritik metriklerdir!\n",
    "</div>\n",
    "\n",
    "> **Ä°pucu:** Daha detaylÄ± Ã¶lÃ§Ã¼mler iÃ§in `psutil`, `torch.cuda.memory_allocated()` gibi araÃ§lar kullanÄ±labilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ef168",
   "metadata": {},
   "source": [
    "## 7. En Ä°yi Uygulamalar (Best Practices)\n",
    "\n",
    "<div style=\"background:#f4fbf4; border-left:6px solid #229954; padding:10px; border-radius:8px;\">\n",
    "âœ… <b>Her zaman</b> <b>torch.no_grad()</b> ile inference yapÄ±n, <b>cihazÄ±</b> otomatik seÃ§in ve <b>memory leak</b> riskine karÅŸÄ± temizlik yapÄ±n!\n",
    "</div>\n",
    "\n",
    "### ğŸ”¹ Performans Optimizasyonu\n",
    "```python\n",
    "# âœ… Ä°yi\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# âŒ KÃ¶tÃ¼\n",
    "outputs = model(**inputs)  # Gradient hesaplanÄ±r\n",
    "```\n",
    "\n",
    "### ğŸ”¹ Device YÃ¶netimi\n",
    "```python\n",
    "# âœ… Ä°yi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# âŒ KÃ¶tÃ¼\n",
    "model = model.to(\"cuda\")  # CUDA olmayabilir\n",
    "```\n",
    "\n",
    "### ğŸ”¹ Memory YÃ¶netimi\n",
    "```python\n",
    "# âœ… Ä°yi\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "\n",
    "# âŒ KÃ¶tÃ¼\n",
    "# Memory leak'e sebep olabilir\n",
    "```\n",
    "\n",
    "<div style=\"background:#fadbd8; border-left:6px solid #C0392B; padding:10px; border-radius:8px;\">\n",
    "ğŸŸ  <b>Flashcard:</b> <b>Pipeline</b> ile <b>AutoTokenizer</b> ve <b>AutoModel</b> arka planda otomatik yÃ¶netilir. <b>Manuel kullanÄ±mda</b> ise cihaz ve memory yÃ¶netimi sizin sorumluluÄŸunuzdadÄ±r!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d684e7f",
   "metadata": {},
   "source": [
    "## 8. Ek Kaynaklar\n",
    "\n",
    "- <span style=\"color:#2980B9;\">[Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/)</span>\n",
    "- <span style=\"color:#229954;\">[PyTorch Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)</span>\n",
    "- <span style=\"color:#C0392B;\">[BERT Paper (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)</span>\n",
    "- <span style=\"color:#CA6F1E;\">[GPT Paper (Radford et al., 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)</span>\n",
    "- <span style=\"color:#8E44AD;\">[T5 Paper (Raffel et al., 2019)](https://arxiv.org/abs/1910.10683)</span>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\" style=\"font-size:1.2em; background:#f4f8fb; border-radius:8px; padding:16px; border:2px solid #CA6F1E;\">\n",
    "  <b>ğŸŒŸ <span style=\"color:#CA6F1E;\">Transformers ile optimize pipeline</span>, <span style=\"color:#229954;\">Ã¼retim kalitesinde NLP'nin anahtarÄ±dÄ±r!</span> ğŸŒŸ</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
